{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\manjw\\.conda\\envs\\dataEngineering\\Lib\\site-packages\\torchaudio\\backend\\utils.py:74: UserWarning: No audio backend is available.\n",
      "  warnings.warn(\"No audio backend is available.\")\n",
      "c:\\Users\\manjw\\.conda\\envs\\dataEngineering\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "import torchmetrics.functional as evafunc\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import torchvision.models as models\n",
    "from segmentation_models_pytorch.losses import DiceLoss, FocalLoss\n",
    "import segmentation_models_pytorch as smp\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自定义数据集类\n",
    "class SpineWeb15(Dataset):\n",
    "    def __init__(self, data_path, transform=None):\n",
    "        self.data_path = data_path\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        file_list = os.listdir(self.data_path)  # 列出文件夹中的所有文件和文件夹\n",
    "        file_count = len(file_list)  # 获取文件数量\n",
    "        return file_count\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        metadata = np.load(self.data_path+str(index)+\".npy\")\n",
    "        image = metadata[0]\n",
    "        label = metadata[1]\n",
    "\n",
    "        image_data = torch.from_numpy(image).float()\n",
    "        label_data = torch.from_numpy(label).float()\n",
    "        \n",
    "        if self.transform:\n",
    "            image_data = self.transform(image_data)\n",
    "            label_data = self.transform(label_data)\n",
    "        return image_data, label_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_pixel_accuracy(prediction, target):\n",
    "    # 将预测结果和目标标签进行逐像素比较，并计算正确预测像素的比例\n",
    "    correct_pixels = (prediction == target).sum().item()\n",
    "    total_pixels = target.numel()\n",
    "    return correct_pixels, total_pixels\n",
    "\n",
    "def calculate_iou(prediction, target):\n",
    "    intersection = torch.logical_and(prediction, target).sum()\n",
    "    union = torch.logical_or(prediction, target).sum()\n",
    "    iou = intersection / union\n",
    "    return iou.item()\n",
    "\n",
    "def calculate_dice(prediction, target):\n",
    "    intersection = torch.logical_and(prediction, target).sum()\n",
    "    dice = (2 * intersection) / (prediction.sum() + target.sum())\n",
    "    return dice.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "DeepLabV3Plus.__init__() got an unexpected keyword argument 'decoder_use_batchnorm'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 32\u001b[0m\n\u001b[0;32m     29\u001b[0m test_loader \u001b[39m=\u001b[39m DataLoader(testset, batch_size\u001b[39m=\u001b[39mbatch_size, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     31\u001b[0m \u001b[39m# 创建模型和优化器\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m model \u001b[39m=\u001b[39m smp\u001b[39m.\u001b[39;49mDeepLabV3Plus(encoder_name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mresnet34\u001b[39;49m\u001b[39m'\u001b[39;49m, encoder_depth\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m, encoder_weights\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mimagenet\u001b[39;49m\u001b[39m\"\u001b[39;49m, decoder_use_batchnorm\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, decoder_channels\u001b[39m=\u001b[39;49m(\u001b[39m256\u001b[39;49m, \u001b[39m128\u001b[39;49m, \u001b[39m64\u001b[39;49m, \u001b[39m32\u001b[39;49m, \u001b[39m16\u001b[39;49m), decoder_attention_type\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, in_channels\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, classes\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, activation\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, aux_params\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m)\n\u001b[0;32m     33\u001b[0m optimizer \u001b[39m=\u001b[39m optim\u001b[39m.\u001b[39mAdam(model\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39mlearning_rate)\n\u001b[0;32m     34\u001b[0m \u001b[39m# criterion = nn.BCEWithLogitsLoss()  # 二分类任务可以使用BCEWithLogitsLoss\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[39m# criterion = DiceLoss(mode=\"binary\")   #DiceLoss\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[39m# criterion = FocalLoss(mode=\"binary\")\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: DeepLabV3Plus.__init__() got an unexpected keyword argument 'decoder_use_batchnorm'"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# UNet++ Train and Test Set\n",
    "# -----------------------------\n",
    "\n",
    "# empty the cache for model and training process\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# set the hyper parameters and the paths 设置超参数和路径\n",
    "data_path = \"./dataset/Spineweb_dataset15/train/\"\n",
    "test_path = \"./dataset/Spineweb_dataset15/test/\"\n",
    "\n",
    "#hyper parameters set\n",
    "batch_size = 32\n",
    "num_epochs = 200\n",
    "learning_rate = 1e-04\n",
    "confidence = 0.7\n",
    "in_channels = 1  # according to demand to adjust the number of channels 根据实际情况修改通道数\n",
    "out_channels = 1  # according to demand to adjust the number of channels 根据实际情况修改通道数\n",
    "\n",
    "# 创建数据集和数据加载器\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),  # 转换为 PIL 图像对象\n",
    "    transforms.Resize((128, 128)),  # 调整大小为 128x128\n",
    "    transforms.ToTensor()  # 转换为张量\n",
    "])\n",
    "dataset = SpineWeb15(data_path=data_path, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "testset = SpineWeb15(data_path=test_path, transform=transform)\n",
    "test_loader = DataLoader(testset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# 创建模型和优化器\n",
    "model = smp.DeepLabV3Plus(encoder_name='resnet34', encoder_depth=5, encoder_weights='imagenet', encoder_output_stride=16, decoder_channels=256, decoder_atrous_rates=(12, 24, 36), in_channels=1, classes=1, activation=None, upsampling=4, aux_params=None)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "# criterion = nn.BCEWithLogitsLoss()  # 二分类任务可以使用BCEWithLogitsLoss\n",
    "# criterion = DiceLoss(mode=\"binary\")   #DiceLoss\n",
    "# criterion = FocalLoss(mode=\"binary\")\n",
    "criterion = smp.losses.TverskyLoss(mode=\"binary\")\n",
    "# criterion = smp.losses.LovaszLoss(mode=\"binary\")\n",
    "\n",
    "# 设置设备\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# check the parameters of the model could be trained 检查模型的参数是否设置为可训练\n",
    "# for name, param in model.named_parameters():\n",
    "#     print(f\"Parameter: {name}, Requires Grad: {param.requires_grad}\")\n",
    "\n",
    "best_loss_train = 100.0\n",
    "best_IoU_train = 0.0\n",
    "best_Dice_train = 0.0\n",
    "\n",
    "best_IoU_test = 0.0\n",
    "best_Dice_test = 0.0\n",
    "\n",
    "best_acc_train = 0.0\n",
    "best_acc_test = 0.0\n",
    "\n",
    "loss_train_list = []\n",
    "IoU_train_list = []\n",
    "Dice_train_list = []\n",
    "IoU_test_list = []\n",
    "Dice_test_list = []\n",
    "acc_train_list = []\n",
    "acc_test_list = []\n",
    "\n",
    "# 训练模型\n",
    "for epoch in range(num_epochs):\n",
    "    # torch.cuda.empty_cache()\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    total_iou = 0.0\n",
    "    total_dice = 0.0\n",
    "    total_iou_test = 0.0\n",
    "    total_dice_test = 0.0\n",
    "    total_acc_train = 0.0\n",
    "    total_acc_test = 0.0\n",
    "    total_correct_pixels = 0\n",
    "    total_pixels = 0\n",
    "    total_correct_pixels_test = 0\n",
    "    total_pixels_test = 0\n",
    "\n",
    "    if epoch > 100:\n",
    "        confidence = 0.9\n",
    "\n",
    "    for images, labels in dataloader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(images)\n",
    "        # squeeze the dimension that pytorch add for channels\n",
    "        outputs = outputs.squeeze(1)     # tensor size ([16,128,128])\n",
    "        labels = labels.squeeze(1)\n",
    "        # apply sigmoid on the outputs\n",
    "        outputs = torch.sigmoid(outputs)\n",
    "        # process the result, bigger than confidence is reliable\n",
    "        predicted = (outputs > confidence).float()     # tensor size ([16,128,128]), True->1.0 and False->0.0\n",
    "        intersection = torch.logical_and(predicted, labels).sum((1, 2))\n",
    "        union = torch.logical_or(predicted, labels).sum((1, 2))\n",
    "        iou = (intersection / (union + 1e-7))  # 每个样本的IoU\n",
    "        dice = (2 * intersection / (predicted.sum((1, 2)) + labels.sum((1, 2))+1e-7))  # 每个样本的Dice Coefficient\n",
    "        # 计算训练集的像素精度\n",
    "        batch_correct_pixels,bacth_total_pixels = calculate_pixel_accuracy(predicted, labels)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        total_iou += torch.sum(iou).item()\n",
    "        total_dice += torch.sum(dice).item()\n",
    "        total_correct_pixels += batch_correct_pixels\n",
    "        total_pixels += bacth_total_pixels\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # train set results\n",
    "    avg_loss = train_loss / len(dataset)\n",
    "    avg_iou = total_iou / len(dataset)\n",
    "    avg_dice = total_dice / len(dataset)\n",
    "    avg_acc_train = total_correct_pixels / total_pixels\n",
    "\n",
    "    # test set results\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_loader:     \n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            # squeeze the dimension that pytorch add for channels\n",
    "            outputs = outputs.squeeze(1)     # tensor size ([16,128,128])\n",
    "            targets = targets.squeeze(1)\n",
    "            outputs = torch.sigmoid(outputs)\n",
    "            # process the result, bigger than 0.5 is reliable\n",
    "            predicted = (outputs > confidence).float()     # tensor size ([16,128,128])\n",
    "            intersection = torch.logical_and(predicted, targets).sum((1, 2))\n",
    "            union = torch.logical_or(predicted, targets).sum((1, 2))\n",
    "            iou = (intersection / (union + 1e-7))  # 每个样本的IoU\n",
    "            dice = (2 * intersection / (predicted.sum((1, 2)) + targets.sum((1, 2))+1e-7))  # 每个样本的Dice Coefficient\n",
    "\n",
    "\n",
    "            batch_correct_pixels,batch_total_pixels = calculate_pixel_accuracy(predicted, targets)\n",
    "            total_iou_test += torch.sum(iou).item()\n",
    "            total_dice_test += torch.sum(dice).item()\n",
    "            total_correct_pixels_test += batch_correct_pixels\n",
    "            total_pixels_test += batch_total_pixels\n",
    "\n",
    "    test_iou = total_iou_test / len(testset)\n",
    "    test_dice = total_dice_test / len(testset)\n",
    "    test_acc = total_correct_pixels_test / total_pixels_test\n",
    "\n",
    "    # get the best IoU and Dice\n",
    "    best_loss_train = best_loss_train if best_loss_train < avg_loss else avg_loss\n",
    "    best_IoU_train = best_IoU_train if best_IoU_train > avg_iou else avg_iou\n",
    "    best_Dice_train = best_Dice_train if best_Dice_train > avg_dice else avg_dice\n",
    "    best_IoU_test = best_IoU_test if best_IoU_test > test_iou else test_iou\n",
    "    # best_Dice_test = best_Dice_test if best_Dice_test > test_dice else test_dice\n",
    "\n",
    "    if(best_Dice_test <= test_dice):\n",
    "        best_Dice_test = test_dice\n",
    "        torch.save(model.state_dict(), f\"./model/DeepLabV3+_checkpoint.pth\")\n",
    "\n",
    "    # get the best accuracy of the trainloader and testloader\n",
    "    best_acc_train = best_acc_train if best_acc_train > avg_acc_train else avg_acc_train\n",
    "    best_acc_test = best_acc_test if best_acc_test > test_acc else test_acc\n",
    "\n",
    "    # store the data in each epoch\n",
    "    loss_train_list.append(avg_loss)\n",
    "    IoU_train_list.append(avg_iou)\n",
    "    Dice_train_list.append(avg_dice)\n",
    "    IoU_test_list.append(test_iou)\n",
    "    Dice_test_list.append(test_dice)\n",
    "    acc_train_list.append(avg_acc_train)\n",
    "    acc_test_list.append(test_acc)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Avg Loss: {avg_loss:.5f}, Avg IoU: {avg_iou:.4f}, Avg Dice: {avg_dice:.4f},Test IoU: {test_iou:.4f}, Test Dice: {test_dice:.4f}, Train Acc: {avg_acc_train:.4f}, Test Acc: {test_acc:.4f}\")\n",
    "    \n",
    "print(\"-----------------------------------------\")\n",
    "print(f\"Best Loss: {best_loss_train:.4f}, Best Train IoU: {best_IoU_train:.4f}, Best Train Dice: {best_Dice_train:.4f}, Best Test IoU: {best_IoU_test:.4f}, Best Test Dice: {best_Dice_test:.4f}, Best Train Acc: {best_acc_train:.4f}, Best Test Acc: {best_acc_test:.4f}\")\n",
    "# draw the plot for the loss and dice\n",
    "# 定义epochs的数量，用于x轴坐标\n",
    "epochs = len(loss_train_list)\n",
    "fit,(ax1,ax2) = plt.subplots(2,1,figsize=(8,8))\n",
    "# 绘制训练损失曲线\n",
    "ax1.plot(range(1, epochs + 1), loss_train_list, label='Train Loss')\n",
    "# 设置图例1\n",
    "ax1.legend()\n",
    "ax1.set_xlabel('Epochs')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('Training Loss')\n",
    "ax1.grid(True)\n",
    "# 绘制IoU和Dice\n",
    "ax2.plot(range(1,epochs +1),IoU_train_list,label='Train IoU')\n",
    "ax2.plot(range(1,epochs +1),Dice_train_list,label='Train Dice')\n",
    "# 设置图例2\n",
    "ax2.legend()\n",
    "ax2.set_xlabel('Epochs')\n",
    "ax2.set_ylabel('IoU and Dice')\n",
    "ax2.set_title('Training IoU and Dice')\n",
    "ax2.grid(True)\n",
    "# show the plots\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# empty the cache for model and training process\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Test IoU: 0.6269, Best Test Dice: 0.7763 Best Test Acc: 0.9749\n"
     ]
    }
   ],
   "source": [
    "# Using the best model to evaluate on the test set\n",
    "\n",
    "model = smp.DeepLabV3Plus(encoder_name='resnet34', encoder_depth=5, encoder_weights='imagenet', encoder_output_stride=16, decoder_channels=256, decoder_atrous_rates=(12, 24, 36), in_channels=1, classes=1, activation=None, upsampling=4, aux_params=None)\n",
    "\n",
    "# 设置设备\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "test_path = \"./dataset/Spineweb_dataset15/test/\"\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),  # 转换为 PIL 图像对象\n",
    "    transforms.Resize((128, 128)),  # 调整大小为 128x128\n",
    "    transforms.ToTensor()  # 转换为张量\n",
    "])\n",
    "\n",
    "# 加载已保存的模型参数\n",
    "checkpoint_path = \"./model/DeepLabV3+_checkpoint.pth.pth\"  # 模型文件路径\n",
    "checkpoint = torch.load(checkpoint_path)\n",
    "model.load_state_dict(checkpoint)\n",
    "\n",
    "# 设置模型为推理模式\n",
    "model.eval()\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "confidence = 0.9\n",
    "\n",
    "testset = SpineWeb15(data_path=test_path, transform=transform)\n",
    "test_loader = DataLoader(testset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# data_iter = iter(test_loader)\n",
    "# images, labels = next(data_iter)\n",
    "# print(\"加载的样本数量:\", images.shape[0])\n",
    "\n",
    "total_iou_test = 0.0\n",
    "total_dice_test = 0.0\n",
    "total_acc_test = 0.0\n",
    "total_correct_pixels_test = 0\n",
    "total_pixels_test = 0\n",
    "\n",
    "# test set results\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        outputs = model(inputs)\n",
    "        # squeeze the dimension that pytorch add for channels\n",
    "        outputs = outputs.squeeze(1)     # tensor size ([16,128,128])\n",
    "        targets = targets.squeeze(1)\n",
    "        outputs = torch.sigmoid(outputs)\n",
    "        # process the result, bigger than 0.5 is reliable\n",
    "        predicted = (outputs > confidence).float()     # tensor size ([16,128,128])\n",
    "        intersection = torch.logical_and(predicted, targets).sum((1, 2))\n",
    "        union = torch.logical_or(predicted, targets).sum((1, 2))\n",
    "        iou = (intersection / (union + 1e-7))  # 平均每个样本的IoU\n",
    "        dice = (2 * intersection / (predicted.sum((1, 2)) + targets.sum((1, 2))+1e-7))  # 平均每个样本的Dice Coefficient\n",
    "\n",
    "\n",
    "        batch_correct_pixels,batch_total_pixels = calculate_pixel_accuracy(predicted, targets)\n",
    "        total_iou_test += torch.sum(iou).item()\n",
    "        total_dice_test += torch.sum(dice).item()\n",
    "        total_correct_pixels_test += batch_correct_pixels\n",
    "        total_pixels_test += batch_total_pixels\n",
    "        \n",
    "\n",
    "predicted_npimage = predicted[0].detach().cpu().numpy()\n",
    "targets_npimage = targets[0].detach().cpu().numpy()\n",
    "fig, axes = plt.subplots(2, 1)\n",
    "axes[0].imshow(predicted_npimage)\n",
    "axes[0].set_title('Predicted')\n",
    "axes[1].imshow(targets_npimage)\n",
    "axes[1].set_title('Target')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "test_iou = total_iou_test / len(testset)\n",
    "test_dice = total_dice_test / len(testset)\n",
    "test_acc = total_correct_pixels_test / total_pixels_test\n",
    "\n",
    "# output the result, the result may vary a little due to the resize function in transform\n",
    "print(f\"Best Test IoU: {test_iou:.4f}, Best Test Dice: {test_dice:.4f} Best Test Acc: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataEngineering",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
