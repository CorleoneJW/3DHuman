{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自定义数据集类\n",
    "class SpineWeb15(Dataset):\n",
    "    def __init__(self, data_path, transform=None):\n",
    "        self.data_path = data_path\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data_path)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        metadata = np.load(self.data_path+str(index)+\".npy\")\n",
    "        image = metadata[0]\n",
    "        label = metadata[1]\n",
    "\n",
    "        image_data = torch.from_numpy(image).float()\n",
    "        label_data = torch.from_numpy(label).float()\n",
    "        \n",
    "        if self.transform:\n",
    "            image_data = self.transform(image_data)\n",
    "        return image_data, label_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# U-Net structure\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DoubleConv, self).__init__()\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(UNet, self).__init__()\n",
    "        \n",
    "        # 编码器部分\n",
    "        self.conv1 = DoubleConv(in_channels, 64)\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2)   #64\n",
    "        self.conv2 = DoubleConv(64, 128)\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2)   #32\n",
    "        self.conv3 = DoubleConv(128, 256)\n",
    "        self.maxpool3 = nn.MaxPool2d(kernel_size=2, stride=2)   #16\n",
    "        self.conv4 = DoubleConv(256, 512)\n",
    "        self.maxpool4 = nn.MaxPool2d(kernel_size=2, stride=2)   #8\n",
    "        \n",
    "        # 解码器部分\n",
    "        self.conv5 = DoubleConv(512, 1024)\n",
    "        self.upconv6 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)   #16\n",
    "        self.conv6 = DoubleConv(1024, 512)\n",
    "        self.upconv7 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)    #32\n",
    "        self.conv7 = DoubleConv(512, 256)\n",
    "        self.upconv8 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)    #64\n",
    "        self.conv8 = DoubleConv(256, 128)\n",
    "        self.upconv9 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)     #128 feature map size\n",
    "        self.conv9 = DoubleConv(64, 64)\n",
    "        \n",
    "        # 输出层\n",
    "        self.output = nn.Conv2d(64, out_channels, kernel_size=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # 编码器\n",
    "        c1 = self.conv1(x)\n",
    "        p1 = self.maxpool1(c1)\n",
    "        c2 = self.conv2(p1)\n",
    "        p2 = self.maxpool2(c2)\n",
    "        c3 = self.conv3(p2)\n",
    "        p3 = self.maxpool3(c3)\n",
    "        c4 = self.conv4(p3)\n",
    "        p4 = self.maxpool4(c4)\n",
    "        \n",
    "        # 解码器\n",
    "        u5 = self.conv5(p4)\n",
    "        u5 = self.upconv6(u5)\n",
    "        u5 = torch.cat((u5, c4), dim=1)\n",
    "        c6 = self.conv6(u5)\n",
    "        u6 = self.upconv7(c6)\n",
    "        u6 = torch.cat((u6, c3), dim=1)\n",
    "        c7 = self.conv7(u6)\n",
    "        u7 = self.upconv8(c7)\n",
    "        u7 = torch.cat((u7, c2), dim=1)\n",
    "        c8 = self.conv8(u7)\n",
    "        u8 = self.upconv9(c8)\n",
    "        c9 = self.conv9(u8)\n",
    "        \n",
    "        # 输出层\n",
    "        output = self.output(c9)\n",
    "        return output\n",
    "\n",
    "# 创建UNet模型实例\n",
    "model = UNet(in_channels=1, out_channels=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/200], Avg Loss: 0.6508, Avg IoU: 0.0154, Avg Dice: 0.0296\n",
      "Epoch [2/200], Avg Loss: 0.6330, Avg IoU: 0.0323, Avg Dice: 0.0592\n",
      "Epoch [3/200], Avg Loss: 0.6157, Avg IoU: 0.0612, Avg Dice: 0.1043\n",
      "Epoch [4/200], Avg Loss: 0.5860, Avg IoU: 0.1917, Avg Dice: 0.2688\n",
      "Epoch [5/200], Avg Loss: 0.5525, Avg IoU: 0.2349, Avg Dice: 0.3161\n",
      "Epoch [6/200], Avg Loss: 0.5164, Avg IoU: 0.2903, Avg Dice: 0.3766\n",
      "Epoch [7/200], Avg Loss: 0.4816, Avg IoU: 0.3183, Avg Dice: 0.4107\n",
      "Epoch [8/200], Avg Loss: 0.4594, Avg IoU: 0.3096, Avg Dice: 0.3928\n",
      "Epoch [9/200], Avg Loss: 0.4259, Avg IoU: 0.2971, Avg Dice: 0.3559\n",
      "Epoch [10/200], Avg Loss: 0.4053, Avg IoU: 0.2733, Avg Dice: 0.3252\n",
      "Epoch [11/200], Avg Loss: 0.3861, Avg IoU: 0.3533, Avg Dice: 0.4245\n",
      "Epoch [12/200], Avg Loss: 0.3717, Avg IoU: 0.4178, Avg Dice: 0.4885\n",
      "Epoch [13/200], Avg Loss: 0.3581, Avg IoU: 0.4352, Avg Dice: 0.5008\n",
      "Epoch [14/200], Avg Loss: 0.3517, Avg IoU: 0.2999, Avg Dice: 0.3499\n",
      "Epoch [15/200], Avg Loss: 0.3415, Avg IoU: 0.4234, Avg Dice: 0.4921\n",
      "Epoch [16/200], Avg Loss: 0.3495, Avg IoU: 0.2927, Avg Dice: 0.3572\n",
      "Epoch [17/200], Avg Loss: 0.3376, Avg IoU: 0.3062, Avg Dice: 0.3602\n",
      "Epoch [18/200], Avg Loss: 0.3265, Avg IoU: 0.3834, Avg Dice: 0.4511\n",
      "Epoch [19/200], Avg Loss: 0.3226, Avg IoU: 0.4264, Avg Dice: 0.4933\n",
      "Epoch [20/200], Avg Loss: 0.3222, Avg IoU: 0.3015, Avg Dice: 0.3566\n",
      "Epoch [21/200], Avg Loss: 0.3176, Avg IoU: 0.3424, Avg Dice: 0.4016\n",
      "Epoch [22/200], Avg Loss: 0.3126, Avg IoU: 0.3862, Avg Dice: 0.4534\n",
      "Epoch [23/200], Avg Loss: 0.3088, Avg IoU: 0.4491, Avg Dice: 0.5125\n",
      "Epoch [24/200], Avg Loss: 0.3074, Avg IoU: 0.4296, Avg Dice: 0.4823\n",
      "Epoch [25/200], Avg Loss: 0.3059, Avg IoU: 0.3779, Avg Dice: 0.4281\n",
      "Epoch [26/200], Avg Loss: 0.3036, Avg IoU: 0.3812, Avg Dice: 0.4306\n",
      "Epoch [27/200], Avg Loss: 0.3001, Avg IoU: 0.4254, Avg Dice: 0.4835\n",
      "Epoch [28/200], Avg Loss: 0.2976, Avg IoU: 0.4933, Avg Dice: 0.5483\n",
      "Epoch [29/200], Avg Loss: 0.2986, Avg IoU: 0.4811, Avg Dice: 0.5382\n",
      "Epoch [30/200], Avg Loss: 0.2937, Avg IoU: 0.4875, Avg Dice: 0.5415\n",
      "Epoch [31/200], Avg Loss: 0.2916, Avg IoU: 0.4878, Avg Dice: 0.5447\n",
      "Epoch [32/200], Avg Loss: 0.2934, Avg IoU: 0.4040, Avg Dice: 0.4488\n",
      "Epoch [33/200], Avg Loss: 0.2882, Avg IoU: 0.4173, Avg Dice: 0.4573\n",
      "Epoch [34/200], Avg Loss: 0.3147, Avg IoU: 0.3433, Avg Dice: 0.3941\n",
      "Epoch [35/200], Avg Loss: 0.2927, Avg IoU: 0.4880, Avg Dice: 0.5489\n",
      "Epoch [36/200], Avg Loss: 0.2959, Avg IoU: 0.4467, Avg Dice: 0.5185\n",
      "Epoch [37/200], Avg Loss: 0.2880, Avg IoU: 0.4316, Avg Dice: 0.4833\n",
      "Epoch [38/200], Avg Loss: 0.2869, Avg IoU: 0.3310, Avg Dice: 0.3715\n",
      "Epoch [39/200], Avg Loss: 0.2839, Avg IoU: 0.3633, Avg Dice: 0.4052\n",
      "Epoch [40/200], Avg Loss: 0.2813, Avg IoU: 0.4022, Avg Dice: 0.4472\n",
      "Epoch [41/200], Avg Loss: 0.2870, Avg IoU: 0.2665, Avg Dice: 0.2971\n",
      "Epoch [42/200], Avg Loss: 0.2816, Avg IoU: 0.3643, Avg Dice: 0.4097\n",
      "Epoch [43/200], Avg Loss: 0.2789, Avg IoU: 0.3570, Avg Dice: 0.4047\n",
      "Epoch [44/200], Avg Loss: 0.2764, Avg IoU: 0.4432, Avg Dice: 0.5032\n",
      "Epoch [45/200], Avg Loss: 0.2775, Avg IoU: 0.3841, Avg Dice: 0.4288\n",
      "Epoch [46/200], Avg Loss: 0.2761, Avg IoU: 0.4221, Avg Dice: 0.4745\n",
      "Epoch [47/200], Avg Loss: 0.2757, Avg IoU: 0.4000, Avg Dice: 0.4579\n",
      "Epoch [48/200], Avg Loss: 0.2711, Avg IoU: 0.4500, Avg Dice: 0.4921\n",
      "Epoch [49/200], Avg Loss: 0.2685, Avg IoU: 0.4901, Avg Dice: 0.5356\n",
      "Epoch [50/200], Avg Loss: 0.2681, Avg IoU: 0.4505, Avg Dice: 0.4889\n",
      "Epoch [51/200], Avg Loss: 0.2694, Avg IoU: 0.4503, Avg Dice: 0.4912\n",
      "Epoch [52/200], Avg Loss: 0.2662, Avg IoU: 0.3735, Avg Dice: 0.4024\n",
      "Epoch [53/200], Avg Loss: 0.2663, Avg IoU: 0.4172, Avg Dice: 0.4522\n",
      "Epoch [54/200], Avg Loss: 0.2623, Avg IoU: 0.4256, Avg Dice: 0.4606\n",
      "Epoch [55/200], Avg Loss: 0.2612, Avg IoU: 0.5338, Avg Dice: 0.5733\n",
      "Epoch [56/200], Avg Loss: 0.2603, Avg IoU: 0.4983, Avg Dice: 0.5297\n",
      "Epoch [57/200], Avg Loss: 0.2622, Avg IoU: 0.3876, Avg Dice: 0.4179\n",
      "Epoch [58/200], Avg Loss: 0.2606, Avg IoU: 0.4435, Avg Dice: 0.4744\n",
      "Epoch [59/200], Avg Loss: 0.2573, Avg IoU: 0.4899, Avg Dice: 0.5241\n",
      "Epoch [60/200], Avg Loss: 0.2568, Avg IoU: 0.4814, Avg Dice: 0.5193\n",
      "Epoch [61/200], Avg Loss: 0.2582, Avg IoU: 0.3864, Avg Dice: 0.4172\n",
      "Epoch [62/200], Avg Loss: 0.2532, Avg IoU: 0.4923, Avg Dice: 0.5263\n",
      "Epoch [63/200], Avg Loss: 0.2518, Avg IoU: 0.5170, Avg Dice: 0.5577\n",
      "Epoch [64/200], Avg Loss: 0.2534, Avg IoU: 0.5010, Avg Dice: 0.5313\n",
      "Epoch [65/200], Avg Loss: 0.2537, Avg IoU: 0.4476, Avg Dice: 0.4768\n",
      "Epoch [66/200], Avg Loss: 0.2491, Avg IoU: 0.5454, Avg Dice: 0.5809\n",
      "Epoch [67/200], Avg Loss: 0.2496, Avg IoU: 0.4943, Avg Dice: 0.5276\n",
      "Epoch [68/200], Avg Loss: 0.2518, Avg IoU: 0.4388, Avg Dice: 0.4716\n",
      "Epoch [69/200], Avg Loss: 0.2455, Avg IoU: 0.5172, Avg Dice: 0.5405\n",
      "Epoch [70/200], Avg Loss: 0.2485, Avg IoU: 0.4484, Avg Dice: 0.4771\n",
      "Epoch [71/200], Avg Loss: 0.2445, Avg IoU: 0.4714, Avg Dice: 0.4901\n",
      "Epoch [72/200], Avg Loss: 0.2446, Avg IoU: 0.4541, Avg Dice: 0.4802\n",
      "Epoch [73/200], Avg Loss: 0.2481, Avg IoU: 0.4750, Avg Dice: 0.5161\n",
      "Epoch [74/200], Avg Loss: 0.2440, Avg IoU: 0.4538, Avg Dice: 0.4801\n",
      "Epoch [75/200], Avg Loss: 0.2434, Avg IoU: 0.4053, Avg Dice: 0.4284\n",
      "Epoch [76/200], Avg Loss: 0.2396, Avg IoU: 0.5099, Avg Dice: 0.5362\n",
      "Epoch [77/200], Avg Loss: 0.2425, Avg IoU: 0.4442, Avg Dice: 0.4738\n",
      "Epoch [78/200], Avg Loss: 0.2369, Avg IoU: 0.5605, Avg Dice: 0.5898\n",
      "Epoch [79/200], Avg Loss: 0.2395, Avg IoU: 0.5166, Avg Dice: 0.5401\n",
      "Epoch [80/200], Avg Loss: 0.2384, Avg IoU: 0.4137, Avg Dice: 0.4326\n",
      "Epoch [81/200], Avg Loss: 0.2405, Avg IoU: 0.4857, Avg Dice: 0.5217\n",
      "Epoch [82/200], Avg Loss: 0.2380, Avg IoU: 0.4134, Avg Dice: 0.4320\n",
      "Epoch [83/200], Avg Loss: 0.2344, Avg IoU: 0.5063, Avg Dice: 0.5336\n",
      "Epoch [84/200], Avg Loss: 0.2336, Avg IoU: 0.5084, Avg Dice: 0.5344\n",
      "Epoch [85/200], Avg Loss: 0.2321, Avg IoU: 0.5724, Avg Dice: 0.5959\n",
      "Epoch [86/200], Avg Loss: 0.2300, Avg IoU: 0.6113, Avg Dice: 0.6420\n",
      "Epoch [87/200], Avg Loss: 0.2323, Avg IoU: 0.4713, Avg Dice: 0.4902\n",
      "Epoch [88/200], Avg Loss: 0.2311, Avg IoU: 0.5196, Avg Dice: 0.5417\n",
      "Epoch [89/200], Avg Loss: 0.2287, Avg IoU: 0.5225, Avg Dice: 0.5435\n",
      "Epoch [90/200], Avg Loss: 0.2289, Avg IoU: 0.5229, Avg Dice: 0.5438\n",
      "Epoch [91/200], Avg Loss: 0.2271, Avg IoU: 0.5790, Avg Dice: 0.5998\n",
      "Epoch [92/200], Avg Loss: 0.2245, Avg IoU: 0.6167, Avg Dice: 0.6455\n",
      "Epoch [93/200], Avg Loss: 0.2248, Avg IoU: 0.5868, Avg Dice: 0.6041\n",
      "Epoch [94/200], Avg Loss: 0.2247, Avg IoU: 0.5373, Avg Dice: 0.5515\n",
      "Epoch [95/200], Avg Loss: 0.2248, Avg IoU: 0.5346, Avg Dice: 0.5501\n",
      "Epoch [96/200], Avg Loss: 0.2220, Avg IoU: 0.4812, Avg Dice: 0.4956\n",
      "Epoch [97/200], Avg Loss: 0.2216, Avg IoU: 0.5351, Avg Dice: 0.5504\n",
      "Epoch [98/200], Avg Loss: 0.2198, Avg IoU: 0.5343, Avg Dice: 0.5500\n",
      "Epoch [99/200], Avg Loss: 0.2223, Avg IoU: 0.5275, Avg Dice: 0.5462\n",
      "Epoch [100/200], Avg Loss: 0.2200, Avg IoU: 0.5413, Avg Dice: 0.5536\n",
      "Epoch [101/200], Avg Loss: 0.2190, Avg IoU: 0.5360, Avg Dice: 0.5508\n",
      "Epoch [102/200], Avg Loss: 0.2197, Avg IoU: 0.5830, Avg Dice: 0.6018\n",
      "Epoch [103/200], Avg Loss: 0.2200, Avg IoU: 0.5280, Avg Dice: 0.5465\n",
      "Epoch [104/200], Avg Loss: 0.2151, Avg IoU: 0.5796, Avg Dice: 0.6002\n",
      "Epoch [105/200], Avg Loss: 0.2192, Avg IoU: 0.4704, Avg Dice: 0.4896\n",
      "Epoch [106/200], Avg Loss: 0.2143, Avg IoU: 0.5873, Avg Dice: 0.6043\n",
      "Epoch [107/200], Avg Loss: 0.2140, Avg IoU: 0.5303, Avg Dice: 0.5474\n",
      "Epoch [108/200], Avg Loss: 0.2114, Avg IoU: 0.5390, Avg Dice: 0.5524\n",
      "Epoch [109/200], Avg Loss: 0.2131, Avg IoU: 0.5439, Avg Dice: 0.5551\n",
      "Epoch [110/200], Avg Loss: 0.2099, Avg IoU: 0.6236, Avg Dice: 0.6490\n",
      "Epoch [111/200], Avg Loss: 0.2128, Avg IoU: 0.4891, Avg Dice: 0.4998\n",
      "Epoch [112/200], Avg Loss: 0.2122, Avg IoU: 0.5425, Avg Dice: 0.5544\n",
      "Epoch [113/200], Avg Loss: 0.2076, Avg IoU: 0.5816, Avg Dice: 0.6013\n",
      "Epoch [114/200], Avg Loss: 0.2123, Avg IoU: 0.4183, Avg Dice: 0.4354\n",
      "Epoch [115/200], Avg Loss: 0.2069, Avg IoU: 0.5873, Avg Dice: 0.6044\n",
      "Epoch [116/200], Avg Loss: 0.2060, Avg IoU: 0.6185, Avg Dice: 0.6454\n",
      "Epoch [117/200], Avg Loss: 0.2082, Avg IoU: 0.5392, Avg Dice: 0.5525\n",
      "Epoch [118/200], Avg Loss: 0.2047, Avg IoU: 0.5928, Avg Dice: 0.6073\n",
      "Epoch [119/200], Avg Loss: 0.2041, Avg IoU: 0.5935, Avg Dice: 0.6088\n",
      "Epoch [120/200], Avg Loss: 0.2038, Avg IoU: 0.5418, Avg Dice: 0.5551\n",
      "Epoch [121/200], Avg Loss: 0.2036, Avg IoU: 0.5454, Avg Dice: 0.5590\n",
      "Epoch [122/200], Avg Loss: 0.2033, Avg IoU: 0.5421, Avg Dice: 0.5562\n",
      "Epoch [123/200], Avg Loss: 0.2018, Avg IoU: 0.5395, Avg Dice: 0.5550\n",
      "Epoch [124/200], Avg Loss: 0.2027, Avg IoU: 0.4963, Avg Dice: 0.5137\n",
      "Epoch [125/200], Avg Loss: 0.2000, Avg IoU: 0.5463, Avg Dice: 0.5564\n",
      "Epoch [126/200], Avg Loss: 0.2007, Avg IoU: 0.5905, Avg Dice: 0.6057\n",
      "Epoch [127/200], Avg Loss: 0.1993, Avg IoU: 0.5480, Avg Dice: 0.5572\n",
      "Epoch [128/200], Avg Loss: 0.2010, Avg IoU: 0.4889, Avg Dice: 0.4997\n",
      "Epoch [129/200], Avg Loss: 0.1961, Avg IoU: 0.5864, Avg Dice: 0.6039\n",
      "Epoch [130/200], Avg Loss: 0.1973, Avg IoU: 0.5103, Avg Dice: 0.5286\n",
      "Epoch [131/200], Avg Loss: 0.1964, Avg IoU: 0.5474, Avg Dice: 0.5613\n",
      "Epoch [132/200], Avg Loss: 0.1979, Avg IoU: 0.4941, Avg Dice: 0.5055\n",
      "Epoch [133/200], Avg Loss: 0.1953, Avg IoU: 0.6135, Avg Dice: 0.6412\n",
      "Epoch [134/200], Avg Loss: 0.1946, Avg IoU: 0.5555, Avg Dice: 0.5663\n",
      "Epoch [135/200], Avg Loss: 0.1941, Avg IoU: 0.6083, Avg Dice: 0.6205\n",
      "Epoch [136/200], Avg Loss: 0.1906, Avg IoU: 0.6462, Avg Dice: 0.6669\n",
      "Epoch [137/200], Avg Loss: 0.1930, Avg IoU: 0.6079, Avg Dice: 0.6203\n",
      "Epoch [138/200], Avg Loss: 0.1899, Avg IoU: 0.6054, Avg Dice: 0.6190\n",
      "Epoch [139/200], Avg Loss: 0.1938, Avg IoU: 0.4859, Avg Dice: 0.5027\n",
      "Epoch [140/200], Avg Loss: 0.1940, Avg IoU: 0.4412, Avg Dice: 0.4532\n",
      "Epoch [141/200], Avg Loss: 0.1879, Avg IoU: 0.6439, Avg Dice: 0.6656\n",
      "Epoch [142/200], Avg Loss: 0.1870, Avg IoU: 0.5533, Avg Dice: 0.5638\n",
      "Epoch [143/200], Avg Loss: 0.1891, Avg IoU: 0.4918, Avg Dice: 0.5011\n",
      "Epoch [144/200], Avg Loss: 0.1885, Avg IoU: 0.6019, Avg Dice: 0.6158\n",
      "Epoch [145/200], Avg Loss: 0.1884, Avg IoU: 0.5500, Avg Dice: 0.5633\n",
      "Epoch [146/200], Avg Loss: 0.1869, Avg IoU: 0.6048, Avg Dice: 0.6202\n",
      "Epoch [147/200], Avg Loss: 0.1876, Avg IoU: 0.5517, Avg Dice: 0.5663\n",
      "Epoch [148/200], Avg Loss: 0.1859, Avg IoU: 0.5526, Avg Dice: 0.5662\n",
      "Epoch [149/200], Avg Loss: 0.1871, Avg IoU: 0.5433, Avg Dice: 0.5614\n",
      "Epoch [150/200], Avg Loss: 0.1842, Avg IoU: 0.5526, Avg Dice: 0.5648\n",
      "Epoch [151/200], Avg Loss: 0.1829, Avg IoU: 0.6054, Avg Dice: 0.6184\n",
      "Epoch [152/200], Avg Loss: 0.1834, Avg IoU: 0.5513, Avg Dice: 0.5602\n",
      "Epoch [153/200], Avg Loss: 0.1821, Avg IoU: 0.5533, Avg Dice: 0.5600\n",
      "Epoch [154/200], Avg Loss: 0.1783, Avg IoU: 0.6829, Avg Dice: 0.7115\n",
      "Epoch [155/200], Avg Loss: 0.1853, Avg IoU: 0.4748, Avg Dice: 0.4919\n",
      "Epoch [156/200], Avg Loss: 0.1824, Avg IoU: 0.5034, Avg Dice: 0.5250\n",
      "Epoch [157/200], Avg Loss: 0.1824, Avg IoU: 0.5231, Avg Dice: 0.5439\n",
      "Epoch [158/200], Avg Loss: 0.1806, Avg IoU: 0.5388, Avg Dice: 0.5589\n",
      "Epoch [159/200], Avg Loss: 0.1802, Avg IoU: 0.4950, Avg Dice: 0.5091\n",
      "Epoch [160/200], Avg Loss: 0.1783, Avg IoU: 0.5010, Avg Dice: 0.5126\n",
      "Epoch [161/200], Avg Loss: 0.1781, Avg IoU: 0.5000, Avg Dice: 0.5122\n",
      "Epoch [162/200], Avg Loss: 0.1769, Avg IoU: 0.5552, Avg Dice: 0.5674\n",
      "Epoch [163/200], Avg Loss: 0.1738, Avg IoU: 0.6566, Avg Dice: 0.6736\n",
      "Epoch [164/200], Avg Loss: 0.1772, Avg IoU: 0.5226, Avg Dice: 0.5439\n",
      "Epoch [165/200], Avg Loss: 0.1755, Avg IoU: 0.5457, Avg Dice: 0.5611\n",
      "Epoch [166/200], Avg Loss: 0.1746, Avg IoU: 0.4941, Avg Dice: 0.5075\n",
      "Epoch [167/200], Avg Loss: 0.1724, Avg IoU: 0.5614, Avg Dice: 0.5712\n",
      "Epoch [168/200], Avg Loss: 0.1742, Avg IoU: 0.5071, Avg Dice: 0.5166\n",
      "Epoch [169/200], Avg Loss: 0.1722, Avg IoU: 0.5617, Avg Dice: 0.5718\n",
      "Epoch [170/200], Avg Loss: 0.1728, Avg IoU: 0.5073, Avg Dice: 0.5167\n",
      "Epoch [171/200], Avg Loss: 0.1715, Avg IoU: 0.6203, Avg Dice: 0.6290\n",
      "Epoch [172/200], Avg Loss: 0.1700, Avg IoU: 0.5632, Avg Dice: 0.5724\n",
      "Epoch [173/200], Avg Loss: 0.1718, Avg IoU: 0.6165, Avg Dice: 0.6266\n",
      "Epoch [174/200], Avg Loss: 0.1665, Avg IoU: 0.6756, Avg Dice: 0.7076\n",
      "Epoch [175/200], Avg Loss: 0.1694, Avg IoU: 0.6064, Avg Dice: 0.6207\n",
      "Epoch [176/200], Avg Loss: 0.1702, Avg IoU: 0.6034, Avg Dice: 0.6198\n",
      "Epoch [177/200], Avg Loss: 0.1672, Avg IoU: 0.6532, Avg Dice: 0.6727\n",
      "Epoch [178/200], Avg Loss: 0.1657, Avg IoU: 0.6063, Avg Dice: 0.6212\n",
      "Epoch [179/200], Avg Loss: 0.1684, Avg IoU: 0.4959, Avg Dice: 0.5094\n",
      "Epoch [180/200], Avg Loss: 0.1642, Avg IoU: 0.6166, Avg Dice: 0.6405\n",
      "Epoch [181/200], Avg Loss: 0.1638, Avg IoU: 0.6099, Avg Dice: 0.6235\n",
      "Epoch [182/200], Avg Loss: 0.1653, Avg IoU: 0.5657, Avg Dice: 0.5739\n",
      "Epoch [183/200], Avg Loss: 0.1644, Avg IoU: 0.5539, Avg Dice: 0.5669\n",
      "Epoch [184/200], Avg Loss: 0.1639, Avg IoU: 0.6083, Avg Dice: 0.6225\n",
      "Epoch [185/200], Avg Loss: 0.1627, Avg IoU: 0.6127, Avg Dice: 0.6251\n",
      "Epoch [186/200], Avg Loss: 0.1613, Avg IoU: 0.6118, Avg Dice: 0.6224\n",
      "Epoch [187/200], Avg Loss: 0.1612, Avg IoU: 0.5575, Avg Dice: 0.5661\n",
      "Epoch [188/200], Avg Loss: 0.1609, Avg IoU: 0.5514, Avg Dice: 0.5590\n",
      "Epoch [189/200], Avg Loss: 0.1585, Avg IoU: 0.6658, Avg Dice: 0.6752\n",
      "Epoch [190/200], Avg Loss: 0.1634, Avg IoU: 0.5229, Avg Dice: 0.5448\n",
      "Epoch [191/200], Avg Loss: 0.1612, Avg IoU: 0.5494, Avg Dice: 0.5636\n",
      "Epoch [192/200], Avg Loss: 0.1602, Avg IoU: 0.4986, Avg Dice: 0.5111\n",
      "Epoch [193/200], Avg Loss: 0.1594, Avg IoU: 0.5626, Avg Dice: 0.5721\n",
      "Epoch [194/200], Avg Loss: 0.1576, Avg IoU: 0.6752, Avg Dice: 0.6844\n",
      "Epoch [195/200], Avg Loss: 0.1601, Avg IoU: 0.4514, Avg Dice: 0.4607\n",
      "Epoch [196/200], Avg Loss: 0.1565, Avg IoU: 0.5644, Avg Dice: 0.5732\n",
      "Epoch [197/200], Avg Loss: 0.1581, Avg IoU: 0.5099, Avg Dice: 0.5180\n",
      "Epoch [198/200], Avg Loss: 0.1582, Avg IoU: 0.6145, Avg Dice: 0.6260\n",
      "Epoch [199/200], Avg Loss: 0.1539, Avg IoU: 0.5592, Avg Dice: 0.5704\n",
      "Epoch [200/200], Avg Loss: 0.1550, Avg IoU: 0.5641, Avg Dice: 0.5728\n",
      "-----------------------------------------\n",
      "Best Loss: 0.1539, Best IoU: 0.6829, Best Dice: 0.7115\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# UNet All Set\n",
    "# -----------------------------\n",
    "\n",
    "# empty the cache for model and training process\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# set the hyper parameters and the paths 设置超参数和路径\n",
    "data_path = \"./dataset/Spineweb_dataset15/processed/\"\n",
    "\n",
    "#hyper parameters set\n",
    "batch_size = 32\n",
    "num_epochs = 200\n",
    "learning_rate = 0.0001\n",
    "confidence = 0.5\n",
    "in_channels = 1  # according to demand to adjust the number of channels 根据实际情况修改通道数\n",
    "out_channels = 1  # according to demand to adjust the number of channels 根据实际情况修改通道数\n",
    "\n",
    "# 创建数据集和数据加载器\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),  # 转换为 PIL 图像对象\n",
    "    transforms.Resize((128, 128)),  # 调整大小为 128x128\n",
    "    transforms.ToTensor()  # 转换为张量\n",
    "])\n",
    "dataset = SpineWeb15(data_path=data_path,transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# 创建模型和优化器\n",
    "model = UNet(in_channels, out_channels)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.BCEWithLogitsLoss()  # 二分类任务可以使用BCEWithLogitsLoss\n",
    "\n",
    "# 设置设备\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# check the parameters of the model could be trained 检查模型的参数是否设置为可训练\n",
    "# for name, param in model.named_parameters():\n",
    "#     print(f\"Parameter: {name}, Requires Grad: {param.requires_grad}\")\n",
    "\n",
    "best_loss = 100.0\n",
    "best_IoU = 0.0\n",
    "best_Dice = 0.0\n",
    "\n",
    "# 训练模型\n",
    "for epoch in range(num_epochs):\n",
    "    # torch.cuda.empty_cache()\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    total_iou = 0\n",
    "    total_dice = 0\n",
    "\n",
    "    for images, labels in dataloader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(images)\n",
    "        # squeeze the dimension that pytorch add for channels\n",
    "        outputs = outputs.squeeze(1)     # tensor size ([16,128,128])\n",
    "        # process the result, bigger than 0.5 is reliable\n",
    "        predicted = (outputs > confidence).float()     # tensor size ([16,128,128])\n",
    "\n",
    "        intersection = torch.logical_and(predicted, labels).sum((1, 2))\n",
    "        union = torch.logical_or(predicted, labels).sum((1, 2))\n",
    "        iou = (intersection / (union + 1e-7)).mean()  # 平均每个样本的IoU\n",
    "        dice = (2 * intersection / (predicted.sum((1, 2)) + labels.sum((1, 2)) + 1e-7)).mean()  # 平均每个样本的Dice Coefficient\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        total_iou += iou.item()\n",
    "        total_dice += dice.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    avg_loss = train_loss / len(dataloader)\n",
    "    avg_iou = total_iou / len(dataloader)\n",
    "    avg_dice = total_dice / len(dataloader)\n",
    "    \n",
    "    # get the best IoU and Dice\n",
    "    best_loss = best_loss if best_loss < avg_loss else avg_loss\n",
    "    best_IoU = best_IoU if best_IoU > avg_iou else avg_iou\n",
    "    best_Dice = best_Dice if best_Dice > avg_dice else avg_dice\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Avg Loss: {avg_loss:.4f}, Avg IoU: {avg_iou:.4f}, Avg Dice: {avg_dice:.4f}\")\n",
    "print(\"-----------------------------------------\")\n",
    "print(f\"Best Loss: {best_loss:.4f}, Best IoU: {best_IoU:.4f}, Best Dice: {best_Dice:.4f}\")\n",
    "# empty the cache for model and training process\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Avg Loss: 0.9541, Avg IoU: 0.0422, Avg Dice: 0.0767,test IoU: 0.0860, test Dice: 0.1501\n",
      "Epoch [2/10], Avg Loss: 0.9186, Avg IoU: 0.0680, Avg Dice: 0.1190,test IoU: 0.0721, test Dice: 0.1222\n",
      "Epoch [3/10], Avg Loss: 0.8902, Avg IoU: 0.0366, Avg Dice: 0.0626,test IoU: 0.2500, test Dice: 0.3759\n",
      "Epoch [4/10], Avg Loss: 0.8125, Avg IoU: 0.1527, Avg Dice: 0.2295,test IoU: 0.2162, test Dice: 0.3053\n",
      "Epoch [5/10], Avg Loss: 0.7737, Avg IoU: 0.0803, Avg Dice: 0.1264,test IoU: 0.2096, test Dice: 0.2987\n",
      "Epoch [6/10], Avg Loss: 0.7393, Avg IoU: 0.0919, Avg Dice: 0.1444,test IoU: 0.2605, test Dice: 0.3929\n",
      "Epoch [7/10], Avg Loss: 0.6677, Avg IoU: 0.1425, Avg Dice: 0.2072,test IoU: 0.1596, test Dice: 0.2435\n",
      "Epoch [8/10], Avg Loss: 0.6466, Avg IoU: 0.1463, Avg Dice: 0.2104,test IoU: 0.1751, test Dice: 0.2625\n",
      "Epoch [9/10], Avg Loss: 0.6101, Avg IoU: 0.2690, Avg Dice: 0.3614,test IoU: 0.2128, test Dice: 0.3276\n",
      "Epoch [10/10], Avg Loss: 0.5707, Avg IoU: 0.2046, Avg Dice: 0.2755,test IoU: 0.2496, test Dice: 0.3372\n",
      "-----------------------------------------\n",
      "Best Loss: 0.5707, Best Train IoU: 0.2690, Best Train Dice: 0.3614, Best Test IoU: 0.2605, Best Test Dice: 0.3929\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# UNet Train Set\n",
    "# -----------------------------\n",
    "\n",
    "def calculate_iou(prediction, target):\n",
    "    intersection = torch.logical_and(prediction, target).sum()\n",
    "    union = torch.logical_or(prediction, target).sum()\n",
    "    iou = intersection / union\n",
    "    return iou.item()\n",
    "\n",
    "def calculate_dice(prediction, target):\n",
    "    intersection = torch.logical_and(prediction, target).sum()\n",
    "    dice = (2 * intersection) / (prediction.sum() + target.sum())\n",
    "    return dice.item()\n",
    "\n",
    "# empty the cache for model and training process\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# set the hyper parameters and the paths 设置超参数和路径\n",
    "data_path = \"./dataset/Spineweb_dataset15/train/\"\n",
    "test_path = \"./dataset/Spineweb_dataset15/test/\"\n",
    "\n",
    "#hyper parameters set\n",
    "batch_size = 32\n",
    "num_epochs = 10\n",
    "learning_rate = 0.0001\n",
    "confidence = 0.5\n",
    "in_channels = 1  # according to demand to adjust the number of channels 根据实际情况修改通道数\n",
    "out_channels = 1  # according to demand to adjust the number of channels 根据实际情况修改通道数\n",
    "\n",
    "# 创建数据集和数据加载器\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),  # 转换为 PIL 图像对象\n",
    "    transforms.Resize((128, 128)),  # 调整大小为 128x128\n",
    "    transforms.ToTensor()  # 转换为张量\n",
    "])\n",
    "dataset = SpineWeb15(data_path=data_path, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "testset = SpineWeb15(data_path=test_path, transform=transform)\n",
    "test_loader = DataLoader(testset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# 创建模型和优化器\n",
    "model = UNet(in_channels, out_channels)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.BCEWithLogitsLoss()  # 二分类任务可以使用BCEWithLogitsLoss\n",
    "\n",
    "# 设置设备\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# check the parameters of the model could be trained 检查模型的参数是否设置为可训练\n",
    "# for name, param in model.named_parameters():\n",
    "#     print(f\"Parameter: {name}, Requires Grad: {param.requires_grad}\")\n",
    "\n",
    "best_loss_train = 100.0\n",
    "best_IoU_train = 0.0\n",
    "best_Dice_train = 0.0\n",
    "\n",
    "best_IoU_test = 0.0\n",
    "best_Dice_test = 0.0\n",
    "\n",
    "# 训练模型\n",
    "for epoch in range(num_epochs):\n",
    "    # torch.cuda.empty_cache()\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    total_iou = 0\n",
    "    total_dice = 0\n",
    "    total_iou_test = 0\n",
    "    total_dice_test = 0\n",
    "\n",
    "    for images, labels in dataloader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(images)\n",
    "        # squeeze the dimension that pytorch add for channels\n",
    "        outputs = outputs.squeeze(1)     # tensor size ([16,128,128])\n",
    "        # process the result, bigger than 0.5 is reliable\n",
    "        predicted = (outputs > confidence).float()     # tensor size ([16,128,128])\n",
    "\n",
    "        intersection = torch.logical_and(predicted, labels).sum((1, 2))\n",
    "        union = torch.logical_or(predicted, labels).sum((1, 2))\n",
    "        iou = (intersection / (union + 1e-7)).mean()  # 平均每个样本的IoU\n",
    "        dice = (2 * intersection / (predicted.sum((1, 2)) + labels.sum((1, 2)) + 1e-7)).mean()  # 平均每个样本的Dice Coefficient\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        total_iou += iou.item()\n",
    "        total_dice += dice.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # train set results\n",
    "    avg_loss = train_loss / len(dataloader)\n",
    "    avg_iou = total_iou / len(dataloader)\n",
    "    avg_dice = total_dice / len(dataloader)\n",
    "\n",
    "    # test set results\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            # squeeze the dimension that pytorch add for channels\n",
    "            outputs = outputs.squeeze(1)     # tensor size ([16,128,128])\n",
    "            # process the result, bigger than 0.5 is reliable\n",
    "            predicted = (outputs > confidence).float()     # tensor size ([16,128,128])\n",
    "            \n",
    "            intersection = torch.logical_and(predicted, targets).sum((1, 2))\n",
    "            union = torch.logical_or(predicted, targets).sum((1, 2))\n",
    "            iou = (intersection / (union + 1e-7)).mean()  # 平均每个样本的IoU\n",
    "            dice = (2 * intersection / (predicted.sum((1, 2)) + targets.sum((1, 2)) + 1e-7)).mean()  # 平均每个样本的Dice Coefficient\n",
    "\n",
    "            total_iou_test += iou.item()\n",
    "            total_dice_test += dice.item()\n",
    "\n",
    "    test_iou = total_iou_test / len(test_loader)\n",
    "    test_dice = total_dice_test / len(test_loader)\n",
    "\n",
    "    # get the best IoU and Dice\n",
    "    best_loss_train = best_loss_train if best_loss_train < avg_loss else avg_loss\n",
    "    best_IoU_train = best_IoU_train if best_IoU_train > avg_iou else avg_iou\n",
    "    best_Dice_train = best_Dice_train if best_Dice_train > avg_dice else avg_dice\n",
    "    best_IoU_test = best_IoU_test if best_IoU_test > test_iou else test_iou\n",
    "    # best_Dice_test = best_Dice_test if best_Dice_test > test_dice else test_dice\n",
    "\n",
    "    if(best_Dice_test <= test_dice):\n",
    "        best_Dice_test = test_dice\n",
    "        torch.save(model.state_dict(), f\"./model/UNet_checkpoint.pth\")\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Avg Loss: {avg_loss:.4f}, Avg IoU: {avg_iou:.4f}, Avg Dice: {avg_dice:.4f},test IoU: {test_iou:.4f}, test Dice: {test_dice:.4f}\")\n",
    "    \n",
    "print(\"-----------------------------------------\")\n",
    "print(f\"Best Loss: {best_loss_train:.4f}, Best Train IoU: {best_IoU_train:.4f}, Best Train Dice: {best_Dice_train:.4f}, Best Test IoU: {best_IoU_test:.4f}, Best Test Dice: {best_Dice_test:.4f}\")\n",
    "# empty the cache for model and training process\n",
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataEngineering",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
