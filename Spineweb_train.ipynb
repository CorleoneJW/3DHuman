{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自定义数据集类\n",
    "class SpineWeb15(Dataset):\n",
    "    def __init__(self, data_path, transform=None):\n",
    "        self.data_path = data_path\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data_path)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        metadata = np.load(self.data_path+str(index)+\".npy\")\n",
    "        image = metadata[0]\n",
    "        label = metadata[1]\n",
    "\n",
    "        image_data = torch.from_numpy(image).float()\n",
    "        label_data = torch.from_numpy(label).float()\n",
    "        \n",
    "        if self.transform:\n",
    "            image_data = self.transform(image_data)\n",
    "        return image_data, label_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# U-Net structure\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DoubleConv, self).__init__()\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(UNet, self).__init__()\n",
    "        \n",
    "        # 编码器部分\n",
    "        self.conv1 = DoubleConv(in_channels, 64)\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2)   #64\n",
    "        self.conv2 = DoubleConv(64, 128)\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2)   #32\n",
    "        self.conv3 = DoubleConv(128, 256)\n",
    "        self.maxpool3 = nn.MaxPool2d(kernel_size=2, stride=2)   #16\n",
    "        self.conv4 = DoubleConv(256, 512)\n",
    "        self.maxpool4 = nn.MaxPool2d(kernel_size=2, stride=2)   #8\n",
    "        \n",
    "        # 解码器部分\n",
    "        self.conv5 = DoubleConv(512, 1024)\n",
    "        self.upconv6 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)   #16\n",
    "        self.conv6 = DoubleConv(1024, 512)\n",
    "        self.upconv7 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)    #32\n",
    "        self.conv7 = DoubleConv(512, 256)\n",
    "        self.upconv8 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)    #64\n",
    "        self.conv8 = DoubleConv(256, 128)\n",
    "        self.upconv9 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)     #128 feature map size\n",
    "        self.conv9 = DoubleConv(64, 64)\n",
    "        \n",
    "        # 输出层\n",
    "        self.output = nn.Conv2d(64, out_channels, kernel_size=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # 编码器\n",
    "        c1 = self.conv1(x)\n",
    "        p1 = self.maxpool1(c1)\n",
    "        c2 = self.conv2(p1)\n",
    "        p2 = self.maxpool2(c2)\n",
    "        c3 = self.conv3(p2)\n",
    "        p3 = self.maxpool3(c3)\n",
    "        c4 = self.conv4(p3)\n",
    "        p4 = self.maxpool4(c4)\n",
    "        \n",
    "        # 解码器\n",
    "        u5 = self.conv5(p4)\n",
    "        u5 = self.upconv6(u5)\n",
    "        u5 = torch.cat((u5, c4), dim=1)\n",
    "        c6 = self.conv6(u5)\n",
    "        u6 = self.upconv7(c6)\n",
    "        u6 = torch.cat((u6, c3), dim=1)\n",
    "        c7 = self.conv7(u6)\n",
    "        u7 = self.upconv8(c7)\n",
    "        u7 = torch.cat((u7, c2), dim=1)\n",
    "        c8 = self.conv8(u7)\n",
    "        u8 = self.upconv9(c8)\n",
    "        c9 = self.conv9(u8)\n",
    "        \n",
    "        # 输出层\n",
    "        output = self.output(c9)\n",
    "        return output\n",
    "\n",
    "# 创建UNet模型实例\n",
    "model = UNet(in_channels=1, out_channels=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Avg Loss: 0.6908, Avg IoU: 0.0711, Avg Dice: 0.1190\n",
      "Epoch [2/100], Avg Loss: 0.4846, Avg IoU: 0.0977, Avg Dice: 0.1509\n",
      "Epoch [3/100], Avg Loss: 0.3881, Avg IoU: 0.1610, Avg Dice: 0.2228\n",
      "Epoch [4/100], Avg Loss: 0.3460, Avg IoU: 0.1770, Avg Dice: 0.2369\n",
      "Epoch [5/100], Avg Loss: 0.3208, Avg IoU: 0.1846, Avg Dice: 0.2494\n",
      "Epoch [6/100], Avg Loss: 0.2987, Avg IoU: 0.1700, Avg Dice: 0.2292\n",
      "Epoch [7/100], Avg Loss: 0.2781, Avg IoU: 0.2057, Avg Dice: 0.2721\n",
      "Epoch [8/100], Avg Loss: 0.2589, Avg IoU: 0.2582, Avg Dice: 0.3307\n",
      "Epoch [9/100], Avg Loss: 0.2456, Avg IoU: 0.2210, Avg Dice: 0.2878\n",
      "Epoch [10/100], Avg Loss: 0.2310, Avg IoU: 0.2865, Avg Dice: 0.3585\n",
      "Epoch [11/100], Avg Loss: 0.2203, Avg IoU: 0.2888, Avg Dice: 0.3514\n",
      "Epoch [12/100], Avg Loss: 0.2090, Avg IoU: 0.2559, Avg Dice: 0.3191\n",
      "Epoch [13/100], Avg Loss: 0.1982, Avg IoU: 0.2773, Avg Dice: 0.3348\n",
      "Epoch [14/100], Avg Loss: 0.1903, Avg IoU: 0.3196, Avg Dice: 0.3894\n",
      "Epoch [15/100], Avg Loss: 0.1790, Avg IoU: 0.3035, Avg Dice: 0.3601\n",
      "Epoch [16/100], Avg Loss: 0.1728, Avg IoU: 0.3503, Avg Dice: 0.4168\n",
      "Epoch [17/100], Avg Loss: 0.1637, Avg IoU: 0.3874, Avg Dice: 0.4667\n",
      "Epoch [18/100], Avg Loss: 0.1544, Avg IoU: 0.3523, Avg Dice: 0.4059\n",
      "Epoch [19/100], Avg Loss: 0.1476, Avg IoU: 0.3523, Avg Dice: 0.4118\n",
      "Epoch [20/100], Avg Loss: 0.1406, Avg IoU: 0.3473, Avg Dice: 0.4064\n",
      "Epoch [21/100], Avg Loss: 0.1352, Avg IoU: 0.3716, Avg Dice: 0.4396\n",
      "Epoch [22/100], Avg Loss: 0.1286, Avg IoU: 0.3960, Avg Dice: 0.4546\n",
      "Epoch [23/100], Avg Loss: 0.1222, Avg IoU: 0.3782, Avg Dice: 0.4350\n",
      "Epoch [24/100], Avg Loss: 0.1164, Avg IoU: 0.3787, Avg Dice: 0.4358\n",
      "Epoch [25/100], Avg Loss: 0.1118, Avg IoU: 0.4142, Avg Dice: 0.4675\n",
      "Epoch [26/100], Avg Loss: 0.1058, Avg IoU: 0.4170, Avg Dice: 0.4681\n",
      "Epoch [27/100], Avg Loss: 0.1013, Avg IoU: 0.4168, Avg Dice: 0.4665\n",
      "Epoch [28/100], Avg Loss: 0.0980, Avg IoU: 0.4485, Avg Dice: 0.4997\n",
      "Epoch [29/100], Avg Loss: 0.0930, Avg IoU: 0.4355, Avg Dice: 0.4810\n",
      "Epoch [30/100], Avg Loss: 0.0898, Avg IoU: 0.4714, Avg Dice: 0.5240\n",
      "Epoch [31/100], Avg Loss: 0.0871, Avg IoU: 0.3992, Avg Dice: 0.4475\n",
      "Epoch [32/100], Avg Loss: 0.0840, Avg IoU: 0.4666, Avg Dice: 0.5177\n",
      "Epoch [33/100], Avg Loss: 0.0793, Avg IoU: 0.4905, Avg Dice: 0.5360\n",
      "Epoch [34/100], Avg Loss: 0.0805, Avg IoU: 0.4528, Avg Dice: 0.5120\n",
      "Epoch [35/100], Avg Loss: 0.0785, Avg IoU: 0.4631, Avg Dice: 0.5171\n",
      "Epoch [36/100], Avg Loss: 0.0749, Avg IoU: 0.4224, Avg Dice: 0.4758\n",
      "Epoch [37/100], Avg Loss: 0.0709, Avg IoU: 0.4339, Avg Dice: 0.4872\n",
      "Epoch [38/100], Avg Loss: 0.0690, Avg IoU: 0.4657, Avg Dice: 0.5201\n",
      "Epoch [39/100], Avg Loss: 0.0641, Avg IoU: 0.4580, Avg Dice: 0.4945\n",
      "Epoch [40/100], Avg Loss: 0.0625, Avg IoU: 0.4519, Avg Dice: 0.4985\n",
      "Epoch [41/100], Avg Loss: 0.0652, Avg IoU: 0.4018, Avg Dice: 0.4542\n",
      "Epoch [42/100], Avg Loss: 0.0601, Avg IoU: 0.4412, Avg Dice: 0.4934\n",
      "Epoch [43/100], Avg Loss: 0.0582, Avg IoU: 0.4824, Avg Dice: 0.5310\n",
      "Epoch [44/100], Avg Loss: 0.0564, Avg IoU: 0.4485, Avg Dice: 0.4971\n",
      "Epoch [45/100], Avg Loss: 0.0530, Avg IoU: 0.4503, Avg Dice: 0.4897\n",
      "Epoch [46/100], Avg Loss: 0.0504, Avg IoU: 0.4348, Avg Dice: 0.4695\n",
      "Epoch [47/100], Avg Loss: 0.0491, Avg IoU: 0.5001, Avg Dice: 0.5415\n",
      "Epoch [48/100], Avg Loss: 0.0477, Avg IoU: 0.4954, Avg Dice: 0.5278\n",
      "Epoch [49/100], Avg Loss: 0.0448, Avg IoU: 0.5032, Avg Dice: 0.5322\n",
      "Epoch [50/100], Avg Loss: 0.0444, Avg IoU: 0.4404, Avg Dice: 0.4732\n",
      "Epoch [51/100], Avg Loss: 0.0425, Avg IoU: 0.5039, Avg Dice: 0.5325\n",
      "Epoch [52/100], Avg Loss: 0.0406, Avg IoU: 0.5087, Avg Dice: 0.5353\n",
      "Epoch [53/100], Avg Loss: 0.0395, Avg IoU: 0.5083, Avg Dice: 0.5350\n",
      "Epoch [54/100], Avg Loss: 0.0382, Avg IoU: 0.5354, Avg Dice: 0.5622\n",
      "Epoch [55/100], Avg Loss: 0.0372, Avg IoU: 0.5402, Avg Dice: 0.5648\n",
      "Epoch [56/100], Avg Loss: 0.0372, Avg IoU: 0.5284, Avg Dice: 0.5582\n",
      "Epoch [57/100], Avg Loss: 0.0367, Avg IoU: 0.5026, Avg Dice: 0.5295\n",
      "Epoch [58/100], Avg Loss: 0.0384, Avg IoU: 0.5007, Avg Dice: 0.5410\n",
      "Epoch [59/100], Avg Loss: 0.0363, Avg IoU: 0.5132, Avg Dice: 0.5489\n",
      "Epoch [60/100], Avg Loss: 0.0353, Avg IoU: 0.4794, Avg Dice: 0.5220\n",
      "Epoch [61/100], Avg Loss: 0.0332, Avg IoU: 0.5178, Avg Dice: 0.5533\n",
      "Epoch [62/100], Avg Loss: 0.0322, Avg IoU: 0.4608, Avg Dice: 0.4925\n",
      "Epoch [63/100], Avg Loss: 0.0318, Avg IoU: 0.4805, Avg Dice: 0.5148\n",
      "Epoch [64/100], Avg Loss: 0.0309, Avg IoU: 0.5374, Avg Dice: 0.5630\n",
      "Epoch [65/100], Avg Loss: 0.0297, Avg IoU: 0.5108, Avg Dice: 0.5365\n",
      "Epoch [66/100], Avg Loss: 0.0293, Avg IoU: 0.5242, Avg Dice: 0.5553\n",
      "Epoch [67/100], Avg Loss: 0.0285, Avg IoU: 0.5151, Avg Dice: 0.5388\n",
      "Epoch [68/100], Avg Loss: 0.0273, Avg IoU: 0.5410, Avg Dice: 0.5654\n",
      "Epoch [69/100], Avg Loss: 0.0269, Avg IoU: 0.5129, Avg Dice: 0.5376\n",
      "Epoch [70/100], Avg Loss: 0.0287, Avg IoU: 0.5496, Avg Dice: 0.5842\n",
      "Epoch [71/100], Avg Loss: 0.0281, Avg IoU: 0.4983, Avg Dice: 0.5294\n",
      "Epoch [72/100], Avg Loss: 0.0283, Avg IoU: 0.5308, Avg Dice: 0.5644\n",
      "Epoch [73/100], Avg Loss: 0.0263, Avg IoU: 0.5104, Avg Dice: 0.5406\n",
      "Epoch [74/100], Avg Loss: 0.0256, Avg IoU: 0.5091, Avg Dice: 0.5463\n",
      "Epoch [75/100], Avg Loss: 0.0238, Avg IoU: 0.4646, Avg Dice: 0.4867\n",
      "Epoch [76/100], Avg Loss: 0.0239, Avg IoU: 0.5064, Avg Dice: 0.5336\n",
      "Epoch [77/100], Avg Loss: 0.0232, Avg IoU: 0.5475, Avg Dice: 0.5776\n",
      "Epoch [78/100], Avg Loss: 0.0225, Avg IoU: 0.5573, Avg Dice: 0.5826\n",
      "Epoch [79/100], Avg Loss: 0.0222, Avg IoU: 0.5198, Avg Dice: 0.5414\n",
      "Epoch [80/100], Avg Loss: 0.0212, Avg IoU: 0.5235, Avg Dice: 0.5490\n",
      "Epoch [81/100], Avg Loss: 0.0201, Avg IoU: 0.5176, Avg Dice: 0.5360\n",
      "Epoch [82/100], Avg Loss: 0.0197, Avg IoU: 0.5169, Avg Dice: 0.5359\n",
      "Epoch [83/100], Avg Loss: 0.0204, Avg IoU: 0.4974, Avg Dice: 0.5171\n",
      "Epoch [84/100], Avg Loss: 0.0203, Avg IoU: 0.4839, Avg Dice: 0.5090\n",
      "Epoch [85/100], Avg Loss: 0.0280, Avg IoU: 0.4419, Avg Dice: 0.4719\n",
      "Epoch [86/100], Avg Loss: 0.0308, Avg IoU: 0.4182, Avg Dice: 0.4698\n",
      "Epoch [87/100], Avg Loss: 0.0292, Avg IoU: 0.4536, Avg Dice: 0.5020\n",
      "Epoch [88/100], Avg Loss: 0.0276, Avg IoU: 0.4506, Avg Dice: 0.4944\n",
      "Epoch [89/100], Avg Loss: 0.0352, Avg IoU: 0.3679, Avg Dice: 0.4339\n",
      "Epoch [90/100], Avg Loss: 0.0331, Avg IoU: 0.4548, Avg Dice: 0.5218\n",
      "Epoch [91/100], Avg Loss: 0.0278, Avg IoU: 0.4701, Avg Dice: 0.5220\n",
      "Epoch [92/100], Avg Loss: 0.0246, Avg IoU: 0.4562, Avg Dice: 0.4934\n",
      "Epoch [93/100], Avg Loss: 0.0244, Avg IoU: 0.4571, Avg Dice: 0.5047\n",
      "Epoch [94/100], Avg Loss: 0.0220, Avg IoU: 0.5040, Avg Dice: 0.5440\n",
      "Epoch [95/100], Avg Loss: 0.0200, Avg IoU: 0.4727, Avg Dice: 0.5031\n",
      "Epoch [96/100], Avg Loss: 0.0183, Avg IoU: 0.5096, Avg Dice: 0.5356\n",
      "Epoch [97/100], Avg Loss: 0.0192, Avg IoU: 0.5489, Avg Dice: 0.5906\n",
      "Epoch [98/100], Avg Loss: 0.0194, Avg IoU: 0.5003, Avg Dice: 0.5305\n",
      "Epoch [99/100], Avg Loss: 0.0186, Avg IoU: 0.5014, Avg Dice: 0.5307\n",
      "Epoch [100/100], Avg Loss: 0.0171, Avg IoU: 0.5603, Avg Dice: 0.5878\n",
      "-----------------------------------------\n",
      "Best Loss: 0.6908, Best IoU: 0.5603, Best Dice: 0.5906\n"
     ]
    }
   ],
   "source": [
    "# empty the cache for model and training process\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# set the hyper parameters and the paths 设置超参数和路径\n",
    "data_path = \"./dataset/Spineweb_dataset15/processed/\"\n",
    "\n",
    "#hyper parameters set\n",
    "batch_size = 16\n",
    "num_epochs = 100\n",
    "learning_rate = 0.001\n",
    "in_channels = 1  # according to demand to adjust the number of channels 根据实际情况修改通道数\n",
    "out_channels = 1  # according to demand to adjust the number of channels 根据实际情况修改通道数\n",
    "\n",
    "# 创建数据集和数据加载器\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),  # 转换为 PIL 图像对象\n",
    "    transforms.Resize((128, 128)),  # 调整大小为 128x128\n",
    "    transforms.ToTensor()  # 转换为张量\n",
    "])\n",
    "dataset = SpineWeb15(data_path=data_path,transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# 创建模型和优化器\n",
    "model = UNet(in_channels, out_channels)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.BCEWithLogitsLoss()  # 二分类任务可以使用BCEWithLogitsLoss\n",
    "\n",
    "# 设置设备\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# check the parameters of the model could be trained 检查模型的参数是否设置为可训练\n",
    "# for name, param in model.named_parameters():\n",
    "#     print(f\"Parameter: {name}, Requires Grad: {param.requires_grad}\")\n",
    "\n",
    "best_loss = 0.0\n",
    "best_IoU = 0.0\n",
    "best_Dice = 0.0\n",
    "\n",
    "# 训练模型\n",
    "for epoch in range(num_epochs):\n",
    "    torch.cuda.empty_cache()\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    total_iou = 0\n",
    "    total_dice = 0\n",
    "\n",
    "    for images, labels in dataloader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(images)\n",
    "        # squeeze the dimension that pytorch add for channels\n",
    "        outputs = outputs.squeeze(1)     # tensor size ([16,128,128])\n",
    "        # process the result, bigger than 0.5 is reliable\n",
    "        predicted = (outputs > 0.5).float()     # tensor size ([16,128,128])\n",
    "\n",
    "        intersection = torch.logical_and(predicted, labels).sum((1, 2))\n",
    "        union = torch.logical_or(predicted, labels).sum((1, 2))\n",
    "        iou = (intersection / (union + 1e-7)).mean()  # 平均每个样本的IoU\n",
    "        dice = (2 * intersection / (predicted.sum((1, 2)) + labels.sum((1, 2)) + 1e-7)).mean()  # 平均每个样本的Dice Coefficient\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        total_iou += iou.item()\n",
    "        total_dice += dice.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    avg_loss = train_loss / len(dataloader)\n",
    "    avg_iou = total_iou / len(dataloader)\n",
    "    avg_dice = total_dice / len(dataloader)\n",
    "    \n",
    "    # get the best IoU and Dice\n",
    "    best_loss = best_loss if best_loss > avg_loss else avg_loss\n",
    "    best_IoU = best_IoU if best_IoU > avg_iou else avg_iou\n",
    "    best_Dice = best_Dice if best_Dice > avg_dice else avg_dice\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Avg Loss: {avg_loss:.4f}, Avg IoU: {avg_iou:.4f}, Avg Dice: {avg_dice:.4f}\")\n",
    "print(\"-----------------------------------------\")\n",
    "print(f\"Best Loss: {best_loss:.4f}, Best IoU: {avg_iou:.4f}, Best Dice: {best_Dice:.4f}\")\n",
    "# empty the cache for model and training process\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在测试集上评估模型\n",
    "model.eval()\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_dataloader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        test_loss += criterion(outputs, labels).item()\n",
    "\n",
    "test_accuracy = 100 * correct / total\n",
    "print('Test Accuracy: {:.2f}%'.format(test_accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataEngineering",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
