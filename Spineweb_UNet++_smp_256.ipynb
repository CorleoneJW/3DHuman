{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "import torchmetrics.functional as evafunc\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import torchvision.models as models\n",
    "from segmentation_models_pytorch.losses import DiceLoss, FocalLoss\n",
    "import segmentation_models_pytorch as smp\n",
    "import os\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自定义数据集类\n",
    "class SpineWeb15(Dataset):\n",
    "    def __init__(self, data_path,transform1=None,transform2=None):\n",
    "        self.data_path = data_path\n",
    "        self.transform1 = transform1\n",
    "        self.transform2 = transform2\n",
    "        \n",
    "    def __len__(self):\n",
    "        file_list = os.listdir(self.data_path)  # 列出文件夹中的所有文件和文件夹\n",
    "        file_count = len(file_list)  # 获取文件数量\n",
    "        return file_count\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        metadata = np.load(self.data_path+str(index)+\".npy\")\n",
    "        image = metadata[0]\n",
    "        label = metadata[1]\n",
    "\n",
    "        # 找到数组中的最小值和最大值\n",
    "        min_value = np.min(image)\n",
    "        max_value = np.max(image)\n",
    "\n",
    "        # # 将数组元素限制在0到255之间（类似于归一化）\n",
    "        image = (image - min_value) * (255 / (max_value - min_value))\n",
    "\n",
    "        image_data = Image.fromarray(image)\n",
    "        label_data = Image.fromarray(label)\n",
    "        # image_data = torch.from_numpy(image).float()\n",
    "        # label_data = torch.from_numpy(label).float()\n",
    "        \n",
    "        if self.transform1:\n",
    "            image_data = self.transform1(image_data)\n",
    "        if self.transform2:\n",
    "            label_data = self.transform2(label_data)\n",
    "        return image_data, label_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_pixel_accuracy(prediction, target):\n",
    "    # 将预测结果和目标标签进行逐像素比较，并计算正确预测像素的比例\n",
    "    correct_pixels = (prediction == target).sum().item()\n",
    "    total_pixels = target.numel()\n",
    "    return correct_pixels, total_pixels\n",
    "\n",
    "def calculate_iou(prediction, target):\n",
    "    intersection = torch.logical_and(prediction, target).sum()\n",
    "    union = torch.logical_or(prediction, target).sum()\n",
    "    iou = intersection / union\n",
    "    return iou.item()\n",
    "\n",
    "def calculate_dice(prediction, target):\n",
    "    intersection = torch.logical_and(prediction, target).sum()\n",
    "    dice = (2 * intersection) / (prediction.sum() + target.sum())\n",
    "    return dice.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/200], Avg Loss: 0.11307, Avg IoU: 0.5639, Avg Dice: 0.6909,Test IoU: 0.6954, Test Dice: 0.8019, Train Acc: 0.9553, Test Acc: 0.9858\n",
      "Epoch [2/200], Avg Loss: 0.11212, Avg IoU: 0.7481, Avg Dice: 0.8392,Test IoU: 0.7606, Test Dice: 0.8439, Train Acc: 0.9884, Test Acc: 0.9901\n",
      "Epoch [3/200], Avg Loss: 0.11180, Avg IoU: 0.7815, Avg Dice: 0.8613,Test IoU: 0.7852, Test Dice: 0.8596, Train Acc: 0.9907, Test Acc: 0.9917\n",
      "Epoch [4/200], Avg Loss: 0.11167, Avg IoU: 0.7962, Avg Dice: 0.8707,Test IoU: 0.7913, Test Dice: 0.8631, Train Acc: 0.9915, Test Acc: 0.9919\n",
      "Epoch [5/200], Avg Loss: 0.11161, Avg IoU: 0.8089, Avg Dice: 0.8792,Test IoU: 0.7928, Test Dice: 0.8661, Train Acc: 0.9924, Test Acc: 0.9921\n",
      "Epoch [6/200], Avg Loss: 0.11159, Avg IoU: 0.8185, Avg Dice: 0.8853,Test IoU: 0.8043, Test Dice: 0.8724, Train Acc: 0.9929, Test Acc: 0.9929\n",
      "Epoch [7/200], Avg Loss: 0.11157, Avg IoU: 0.8232, Avg Dice: 0.8884,Test IoU: 0.8202, Test Dice: 0.8824, Train Acc: 0.9932, Test Acc: 0.9937\n",
      "Epoch [8/200], Avg Loss: 0.11155, Avg IoU: 0.8281, Avg Dice: 0.8915,Test IoU: 0.8240, Test Dice: 0.8858, Train Acc: 0.9935, Test Acc: 0.9939\n",
      "Epoch [9/200], Avg Loss: 0.11155, Avg IoU: 0.8344, Avg Dice: 0.8956,Test IoU: 0.8361, Test Dice: 0.8923, Train Acc: 0.9938, Test Acc: 0.9946\n",
      "Epoch [10/200], Avg Loss: 0.11153, Avg IoU: 0.8366, Avg Dice: 0.8968,Test IoU: 0.8000, Test Dice: 0.8707, Train Acc: 0.9939, Test Acc: 0.9926\n",
      "Epoch [11/200], Avg Loss: 0.11153, Avg IoU: 0.8310, Avg Dice: 0.8930,Test IoU: 0.8239, Test Dice: 0.8855, Train Acc: 0.9935, Test Acc: 0.9939\n",
      "Epoch [12/200], Avg Loss: 0.11152, Avg IoU: 0.8443, Avg Dice: 0.9018,Test IoU: 0.8193, Test Dice: 0.8819, Train Acc: 0.9943, Test Acc: 0.9936\n",
      "Epoch [13/200], Avg Loss: 0.11152, Avg IoU: 0.8471, Avg Dice: 0.9036,Test IoU: 0.8184, Test Dice: 0.8813, Train Acc: 0.9945, Test Acc: 0.9937\n",
      "Epoch [14/200], Avg Loss: 0.11152, Avg IoU: 0.8455, Avg Dice: 0.9025,Test IoU: 0.8216, Test Dice: 0.8838, Train Acc: 0.9944, Test Acc: 0.9938\n",
      "Epoch [15/200], Avg Loss: 0.11152, Avg IoU: 0.8511, Avg Dice: 0.9060,Test IoU: 0.8286, Test Dice: 0.8882, Train Acc: 0.9946, Test Acc: 0.9942\n",
      "Epoch [16/200], Avg Loss: 0.11152, Avg IoU: 0.8485, Avg Dice: 0.9045,Test IoU: 0.8168, Test Dice: 0.8804, Train Acc: 0.9945, Test Acc: 0.9936\n",
      "Epoch [17/200], Avg Loss: 0.11152, Avg IoU: 0.8537, Avg Dice: 0.9076,Test IoU: 0.8373, Test Dice: 0.8933, Train Acc: 0.9948, Test Acc: 0.9946\n",
      "Epoch [18/200], Avg Loss: 0.11151, Avg IoU: 0.8590, Avg Dice: 0.9110,Test IoU: 0.8330, Test Dice: 0.8911, Train Acc: 0.9950, Test Acc: 0.9944\n",
      "Epoch [19/200], Avg Loss: 0.11151, Avg IoU: 0.8632, Avg Dice: 0.9138,Test IoU: 0.8293, Test Dice: 0.8888, Train Acc: 0.9952, Test Acc: 0.9942\n",
      "Epoch [20/200], Avg Loss: 0.11151, Avg IoU: 0.8627, Avg Dice: 0.9133,Test IoU: 0.8313, Test Dice: 0.8900, Train Acc: 0.9952, Test Acc: 0.9943\n",
      "Epoch [21/200], Avg Loss: 0.11152, Avg IoU: 0.8643, Avg Dice: 0.9143,Test IoU: 0.8328, Test Dice: 0.8913, Train Acc: 0.9953, Test Acc: 0.9944\n",
      "Epoch [22/200], Avg Loss: 0.11151, Avg IoU: 0.8681, Avg Dice: 0.9168,Test IoU: 0.8370, Test Dice: 0.8937, Train Acc: 0.9955, Test Acc: 0.9946\n",
      "Epoch [23/200], Avg Loss: 0.11152, Avg IoU: 0.8661, Avg Dice: 0.9156,Test IoU: 0.8425, Test Dice: 0.8963, Train Acc: 0.9954, Test Acc: 0.9949\n",
      "Epoch [24/200], Avg Loss: 0.11152, Avg IoU: 0.8658, Avg Dice: 0.9152,Test IoU: 0.8335, Test Dice: 0.8910, Train Acc: 0.9954, Test Acc: 0.9945\n",
      "Epoch [25/200], Avg Loss: 0.11151, Avg IoU: 0.8699, Avg Dice: 0.9178,Test IoU: 0.8402, Test Dice: 0.8948, Train Acc: 0.9956, Test Acc: 0.9948\n",
      "Epoch [26/200], Avg Loss: 0.11151, Avg IoU: 0.8723, Avg Dice: 0.9194,Test IoU: 0.8417, Test Dice: 0.8962, Train Acc: 0.9957, Test Acc: 0.9949\n",
      "Epoch [27/200], Avg Loss: 0.11151, Avg IoU: 0.8732, Avg Dice: 0.9200,Test IoU: 0.8422, Test Dice: 0.8964, Train Acc: 0.9958, Test Acc: 0.9949\n",
      "Epoch [28/200], Avg Loss: 0.11152, Avg IoU: 0.8718, Avg Dice: 0.9189,Test IoU: 0.8472, Test Dice: 0.8997, Train Acc: 0.9957, Test Acc: 0.9951\n",
      "Epoch [29/200], Avg Loss: 0.11152, Avg IoU: 0.8623, Avg Dice: 0.9132,Test IoU: 0.8395, Test Dice: 0.8955, Train Acc: 0.9952, Test Acc: 0.9947\n",
      "Epoch [30/200], Avg Loss: 0.11151, Avg IoU: 0.8748, Avg Dice: 0.9211,Test IoU: 0.8424, Test Dice: 0.8972, Train Acc: 0.9958, Test Acc: 0.9949\n",
      "Epoch [31/200], Avg Loss: 0.11151, Avg IoU: 0.8807, Avg Dice: 0.9250,Test IoU: 0.8520, Test Dice: 0.9030, Train Acc: 0.9961, Test Acc: 0.9953\n",
      "Epoch [32/200], Avg Loss: 0.11151, Avg IoU: 0.8829, Avg Dice: 0.9262,Test IoU: 0.8535, Test Dice: 0.9038, Train Acc: 0.9962, Test Acc: 0.9954\n",
      "Epoch [33/200], Avg Loss: 0.11151, Avg IoU: 0.8837, Avg Dice: 0.9267,Test IoU: 0.8469, Test Dice: 0.9007, Train Acc: 0.9962, Test Acc: 0.9951\n",
      "Epoch [34/200], Avg Loss: 0.11151, Avg IoU: 0.8865, Avg Dice: 0.9285,Test IoU: 0.8493, Test Dice: 0.9009, Train Acc: 0.9964, Test Acc: 0.9952\n",
      "Epoch [35/200], Avg Loss: 0.11151, Avg IoU: 0.8843, Avg Dice: 0.9269,Test IoU: 0.8531, Test Dice: 0.9035, Train Acc: 0.9963, Test Acc: 0.9954\n",
      "Epoch [36/200], Avg Loss: 0.11150, Avg IoU: 0.8855, Avg Dice: 0.9280,Test IoU: 0.8539, Test Dice: 0.9042, Train Acc: 0.9963, Test Acc: 0.9954\n",
      "Epoch [37/200], Avg Loss: 0.11151, Avg IoU: 0.8858, Avg Dice: 0.9282,Test IoU: 0.8509, Test Dice: 0.9020, Train Acc: 0.9963, Test Acc: 0.9953\n",
      "Epoch [38/200], Avg Loss: 0.11151, Avg IoU: 0.8867, Avg Dice: 0.9287,Test IoU: 0.8584, Test Dice: 0.9069, Train Acc: 0.9964, Test Acc: 0.9957\n",
      "Epoch [39/200], Avg Loss: 0.11151, Avg IoU: 0.8882, Avg Dice: 0.9295,Test IoU: 0.8545, Test Dice: 0.9046, Train Acc: 0.9965, Test Acc: 0.9955\n",
      "Epoch [40/200], Avg Loss: 0.11150, Avg IoU: 0.8886, Avg Dice: 0.9299,Test IoU: 0.8577, Test Dice: 0.9061, Train Acc: 0.9965, Test Acc: 0.9957\n",
      "Epoch [41/200], Avg Loss: 0.11150, Avg IoU: 0.8908, Avg Dice: 0.9312,Test IoU: 0.8552, Test Dice: 0.9050, Train Acc: 0.9966, Test Acc: 0.9955\n",
      "Epoch [42/200], Avg Loss: 0.11151, Avg IoU: 0.8909, Avg Dice: 0.9313,Test IoU: 0.8571, Test Dice: 0.9064, Train Acc: 0.9966, Test Acc: 0.9956\n",
      "Epoch [43/200], Avg Loss: 0.11151, Avg IoU: 0.8927, Avg Dice: 0.9324,Test IoU: 0.8497, Test Dice: 0.9017, Train Acc: 0.9966, Test Acc: 0.9953\n",
      "Epoch [44/200], Avg Loss: 0.11150, Avg IoU: 0.8934, Avg Dice: 0.9328,Test IoU: 0.8572, Test Dice: 0.9058, Train Acc: 0.9967, Test Acc: 0.9956\n",
      "Epoch [45/200], Avg Loss: 0.11150, Avg IoU: 0.8908, Avg Dice: 0.9312,Test IoU: 0.8575, Test Dice: 0.9064, Train Acc: 0.9966, Test Acc: 0.9957\n",
      "Epoch [46/200], Avg Loss: 0.11150, Avg IoU: 0.8941, Avg Dice: 0.9332,Test IoU: 0.8603, Test Dice: 0.9082, Train Acc: 0.9967, Test Acc: 0.9958\n",
      "Epoch [47/200], Avg Loss: 0.11150, Avg IoU: 0.8935, Avg Dice: 0.9329,Test IoU: 0.8534, Test Dice: 0.9039, Train Acc: 0.9967, Test Acc: 0.9954\n",
      "Epoch [48/200], Avg Loss: 0.11151, Avg IoU: 0.8947, Avg Dice: 0.9336,Test IoU: 0.8485, Test Dice: 0.9009, Train Acc: 0.9967, Test Acc: 0.9952\n",
      "Epoch [49/200], Avg Loss: 0.11150, Avg IoU: 0.8951, Avg Dice: 0.9337,Test IoU: 0.8536, Test Dice: 0.9038, Train Acc: 0.9968, Test Acc: 0.9954\n",
      "Epoch [50/200], Avg Loss: 0.11150, Avg IoU: 0.8966, Avg Dice: 0.9346,Test IoU: 0.8563, Test Dice: 0.9059, Train Acc: 0.9968, Test Acc: 0.9956\n",
      "Epoch [51/200], Avg Loss: 0.11150, Avg IoU: 0.8981, Avg Dice: 0.9355,Test IoU: 0.8559, Test Dice: 0.9056, Train Acc: 0.9969, Test Acc: 0.9956\n",
      "Epoch [52/200], Avg Loss: 0.11150, Avg IoU: 0.8936, Avg Dice: 0.9325,Test IoU: 0.8605, Test Dice: 0.9081, Train Acc: 0.9967, Test Acc: 0.9958\n",
      "Epoch [53/200], Avg Loss: 0.11150, Avg IoU: 0.8950, Avg Dice: 0.9334,Test IoU: 0.8558, Test Dice: 0.9052, Train Acc: 0.9968, Test Acc: 0.9956\n",
      "Epoch [54/200], Avg Loss: 0.11150, Avg IoU: 0.8965, Avg Dice: 0.9344,Test IoU: 0.8586, Test Dice: 0.9072, Train Acc: 0.9968, Test Acc: 0.9957\n",
      "Epoch [55/200], Avg Loss: 0.11151, Avg IoU: 0.8976, Avg Dice: 0.9351,Test IoU: 0.8619, Test Dice: 0.9089, Train Acc: 0.9969, Test Acc: 0.9959\n",
      "Epoch [56/200], Avg Loss: 0.11150, Avg IoU: 0.9005, Avg Dice: 0.9368,Test IoU: 0.8627, Test Dice: 0.9095, Train Acc: 0.9970, Test Acc: 0.9959\n",
      "Epoch [57/200], Avg Loss: 0.11151, Avg IoU: 0.9027, Avg Dice: 0.9381,Test IoU: 0.8625, Test Dice: 0.9093, Train Acc: 0.9971, Test Acc: 0.9959\n",
      "Epoch [58/200], Avg Loss: 0.11150, Avg IoU: 0.9020, Avg Dice: 0.9377,Test IoU: 0.8578, Test Dice: 0.9063, Train Acc: 0.9971, Test Acc: 0.9957\n",
      "Epoch [59/200], Avg Loss: 0.11150, Avg IoU: 0.9022, Avg Dice: 0.9379,Test IoU: 0.8547, Test Dice: 0.9046, Train Acc: 0.9971, Test Acc: 0.9955\n",
      "Epoch [60/200], Avg Loss: 0.11150, Avg IoU: 0.9037, Avg Dice: 0.9388,Test IoU: 0.8597, Test Dice: 0.9078, Train Acc: 0.9971, Test Acc: 0.9957\n",
      "Epoch [61/200], Avg Loss: 0.11150, Avg IoU: 0.9014, Avg Dice: 0.9374,Test IoU: 0.8589, Test Dice: 0.9071, Train Acc: 0.9970, Test Acc: 0.9957\n",
      "Epoch [62/200], Avg Loss: 0.11150, Avg IoU: 0.9038, Avg Dice: 0.9388,Test IoU: 0.8580, Test Dice: 0.9068, Train Acc: 0.9971, Test Acc: 0.9957\n",
      "Epoch [63/200], Avg Loss: 0.11150, Avg IoU: 0.9038, Avg Dice: 0.9388,Test IoU: 0.8644, Test Dice: 0.9104, Train Acc: 0.9971, Test Acc: 0.9960\n",
      "Epoch [64/200], Avg Loss: 0.11150, Avg IoU: 0.9049, Avg Dice: 0.9395,Test IoU: 0.8486, Test Dice: 0.9011, Train Acc: 0.9972, Test Acc: 0.9952\n",
      "Epoch [65/200], Avg Loss: 0.11150, Avg IoU: 0.9049, Avg Dice: 0.9396,Test IoU: 0.8590, Test Dice: 0.9071, Train Acc: 0.9972, Test Acc: 0.9957\n",
      "Epoch [66/200], Avg Loss: 0.11150, Avg IoU: 0.9075, Avg Dice: 0.9410,Test IoU: 0.8599, Test Dice: 0.9076, Train Acc: 0.9973, Test Acc: 0.9958\n",
      "Epoch [67/200], Avg Loss: 0.11150, Avg IoU: 0.8977, Avg Dice: 0.9349,Test IoU: 0.8547, Test Dice: 0.9047, Train Acc: 0.9968, Test Acc: 0.9955\n",
      "Epoch [68/200], Avg Loss: 0.11150, Avg IoU: 0.9028, Avg Dice: 0.9381,Test IoU: 0.8591, Test Dice: 0.9074, Train Acc: 0.9971, Test Acc: 0.9957\n",
      "Epoch [69/200], Avg Loss: 0.11150, Avg IoU: 0.9072, Avg Dice: 0.9407,Test IoU: 0.8619, Test Dice: 0.9090, Train Acc: 0.9973, Test Acc: 0.9958\n",
      "Epoch [70/200], Avg Loss: 0.11150, Avg IoU: 0.9092, Avg Dice: 0.9419,Test IoU: 0.8630, Test Dice: 0.9101, Train Acc: 0.9974, Test Acc: 0.9959\n",
      "Epoch [71/200], Avg Loss: 0.11150, Avg IoU: 0.9098, Avg Dice: 0.9423,Test IoU: 0.8621, Test Dice: 0.9093, Train Acc: 0.9974, Test Acc: 0.9959\n",
      "Epoch [72/200], Avg Loss: 0.11150, Avg IoU: 0.9098, Avg Dice: 0.9422,Test IoU: 0.8592, Test Dice: 0.9075, Train Acc: 0.9974, Test Acc: 0.9957\n",
      "Epoch [73/200], Avg Loss: 0.11150, Avg IoU: 0.9081, Avg Dice: 0.9413,Test IoU: 0.8608, Test Dice: 0.9081, Train Acc: 0.9973, Test Acc: 0.9958\n",
      "Epoch [74/200], Avg Loss: 0.11150, Avg IoU: 0.9100, Avg Dice: 0.9425,Test IoU: 0.8649, Test Dice: 0.9105, Train Acc: 0.9974, Test Acc: 0.9960\n",
      "Epoch [75/200], Avg Loss: 0.11150, Avg IoU: 0.9110, Avg Dice: 0.9430,Test IoU: 0.8625, Test Dice: 0.9092, Train Acc: 0.9974, Test Acc: 0.9959\n",
      "Epoch [76/200], Avg Loss: 0.11149, Avg IoU: 0.9071, Avg Dice: 0.9407,Test IoU: 0.8622, Test Dice: 0.9091, Train Acc: 0.9973, Test Acc: 0.9958\n",
      "Epoch [77/200], Avg Loss: 0.11150, Avg IoU: 0.9096, Avg Dice: 0.9423,Test IoU: 0.8643, Test Dice: 0.9104, Train Acc: 0.9974, Test Acc: 0.9959\n",
      "Epoch [78/200], Avg Loss: 0.11149, Avg IoU: 0.9102, Avg Dice: 0.9425,Test IoU: 0.8587, Test Dice: 0.9070, Train Acc: 0.9974, Test Acc: 0.9957\n",
      "Epoch [79/200], Avg Loss: 0.11149, Avg IoU: 0.9122, Avg Dice: 0.9438,Test IoU: 0.8650, Test Dice: 0.9108, Train Acc: 0.9975, Test Acc: 0.9959\n",
      "Epoch [80/200], Avg Loss: 0.11150, Avg IoU: 0.9130, Avg Dice: 0.9441,Test IoU: 0.8598, Test Dice: 0.9074, Train Acc: 0.9975, Test Acc: 0.9957\n",
      "Epoch [81/200], Avg Loss: 0.11150, Avg IoU: 0.9130, Avg Dice: 0.9442,Test IoU: 0.8628, Test Dice: 0.9092, Train Acc: 0.9975, Test Acc: 0.9959\n",
      "Epoch [82/200], Avg Loss: 0.11149, Avg IoU: 0.9134, Avg Dice: 0.9444,Test IoU: 0.8652, Test Dice: 0.9109, Train Acc: 0.9975, Test Acc: 0.9960\n",
      "Epoch [83/200], Avg Loss: 0.11150, Avg IoU: 0.9131, Avg Dice: 0.9442,Test IoU: 0.8645, Test Dice: 0.9108, Train Acc: 0.9975, Test Acc: 0.9960\n",
      "Epoch [84/200], Avg Loss: 0.11149, Avg IoU: 0.9134, Avg Dice: 0.9443,Test IoU: 0.8668, Test Dice: 0.9118, Train Acc: 0.9975, Test Acc: 0.9961\n",
      "Epoch [85/200], Avg Loss: 0.11149, Avg IoU: 0.9147, Avg Dice: 0.9451,Test IoU: 0.8642, Test Dice: 0.9101, Train Acc: 0.9976, Test Acc: 0.9959\n",
      "Epoch [86/200], Avg Loss: 0.11150, Avg IoU: 0.9154, Avg Dice: 0.9456,Test IoU: 0.8631, Test Dice: 0.9096, Train Acc: 0.9976, Test Acc: 0.9959\n",
      "Epoch [87/200], Avg Loss: 0.11149, Avg IoU: 0.9151, Avg Dice: 0.9453,Test IoU: 0.8646, Test Dice: 0.9104, Train Acc: 0.9976, Test Acc: 0.9960\n",
      "Epoch [88/200], Avg Loss: 0.11149, Avg IoU: 0.9153, Avg Dice: 0.9454,Test IoU: 0.8660, Test Dice: 0.9114, Train Acc: 0.9976, Test Acc: 0.9960\n",
      "Epoch [89/200], Avg Loss: 0.11149, Avg IoU: 0.9161, Avg Dice: 0.9460,Test IoU: 0.8631, Test Dice: 0.9099, Train Acc: 0.9976, Test Acc: 0.9959\n",
      "Epoch [90/200], Avg Loss: 0.11150, Avg IoU: 0.9154, Avg Dice: 0.9455,Test IoU: 0.8646, Test Dice: 0.9102, Train Acc: 0.9976, Test Acc: 0.9960\n",
      "Epoch [91/200], Avg Loss: 0.11149, Avg IoU: 0.9158, Avg Dice: 0.9458,Test IoU: 0.8644, Test Dice: 0.9103, Train Acc: 0.9976, Test Acc: 0.9960\n",
      "Epoch [92/200], Avg Loss: 0.11150, Avg IoU: 0.9169, Avg Dice: 0.9464,Test IoU: 0.8671, Test Dice: 0.9118, Train Acc: 0.9977, Test Acc: 0.9961\n",
      "Epoch [93/200], Avg Loss: 0.11150, Avg IoU: 0.9178, Avg Dice: 0.9469,Test IoU: 0.8621, Test Dice: 0.9091, Train Acc: 0.9977, Test Acc: 0.9958\n",
      "Epoch [94/200], Avg Loss: 0.11150, Avg IoU: 0.9178, Avg Dice: 0.9470,Test IoU: 0.8662, Test Dice: 0.9115, Train Acc: 0.9977, Test Acc: 0.9960\n",
      "Epoch [95/200], Avg Loss: 0.11149, Avg IoU: 0.9177, Avg Dice: 0.9469,Test IoU: 0.8665, Test Dice: 0.9119, Train Acc: 0.9977, Test Acc: 0.9961\n",
      "Epoch [96/200], Avg Loss: 0.11149, Avg IoU: 0.9165, Avg Dice: 0.9461,Test IoU: 0.8665, Test Dice: 0.9116, Train Acc: 0.9977, Test Acc: 0.9961\n",
      "Epoch [97/200], Avg Loss: 0.11150, Avg IoU: 0.9180, Avg Dice: 0.9472,Test IoU: 0.8616, Test Dice: 0.9088, Train Acc: 0.9977, Test Acc: 0.9959\n",
      "Epoch [98/200], Avg Loss: 0.11150, Avg IoU: 0.9181, Avg Dice: 0.9471,Test IoU: 0.8606, Test Dice: 0.9081, Train Acc: 0.9977, Test Acc: 0.9958\n",
      "Epoch [99/200], Avg Loss: 0.11149, Avg IoU: 0.9185, Avg Dice: 0.9474,Test IoU: 0.8662, Test Dice: 0.9115, Train Acc: 0.9977, Test Acc: 0.9960\n",
      "Epoch [100/200], Avg Loss: 0.11150, Avg IoU: 0.9200, Avg Dice: 0.9483,Test IoU: 0.8666, Test Dice: 0.9116, Train Acc: 0.9978, Test Acc: 0.9961\n",
      "Epoch [101/200], Avg Loss: 0.11150, Avg IoU: 0.9192, Avg Dice: 0.9478,Test IoU: 0.8673, Test Dice: 0.9121, Train Acc: 0.9978, Test Acc: 0.9961\n",
      "Epoch [102/200], Avg Loss: 0.11150, Avg IoU: 0.9222, Avg Dice: 0.9494,Test IoU: 0.8634, Test Dice: 0.9095, Train Acc: 0.9979, Test Acc: 0.9959\n",
      "Epoch [103/200], Avg Loss: 0.11150, Avg IoU: 0.9212, Avg Dice: 0.9488,Test IoU: 0.8644, Test Dice: 0.9102, Train Acc: 0.9979, Test Acc: 0.9959\n",
      "Epoch [104/200], Avg Loss: 0.11149, Avg IoU: 0.9211, Avg Dice: 0.9486,Test IoU: 0.8660, Test Dice: 0.9112, Train Acc: 0.9979, Test Acc: 0.9961\n",
      "Epoch [105/200], Avg Loss: 0.11149, Avg IoU: 0.9206, Avg Dice: 0.9485,Test IoU: 0.8651, Test Dice: 0.9108, Train Acc: 0.9978, Test Acc: 0.9960\n",
      "Epoch [106/200], Avg Loss: 0.11150, Avg IoU: 0.9209, Avg Dice: 0.9486,Test IoU: 0.8674, Test Dice: 0.9120, Train Acc: 0.9978, Test Acc: 0.9961\n",
      "Epoch [107/200], Avg Loss: 0.11149, Avg IoU: 0.9219, Avg Dice: 0.9493,Test IoU: 0.8689, Test Dice: 0.9130, Train Acc: 0.9979, Test Acc: 0.9962\n",
      "Epoch [108/200], Avg Loss: 0.11149, Avg IoU: 0.9235, Avg Dice: 0.9501,Test IoU: 0.8670, Test Dice: 0.9119, Train Acc: 0.9979, Test Acc: 0.9961\n",
      "Epoch [109/200], Avg Loss: 0.11150, Avg IoU: 0.9231, Avg Dice: 0.9499,Test IoU: 0.8649, Test Dice: 0.9103, Train Acc: 0.9979, Test Acc: 0.9960\n",
      "Epoch [110/200], Avg Loss: 0.11149, Avg IoU: 0.9237, Avg Dice: 0.9502,Test IoU: 0.8641, Test Dice: 0.9100, Train Acc: 0.9980, Test Acc: 0.9960\n",
      "Epoch [111/200], Avg Loss: 0.11149, Avg IoU: 0.9225, Avg Dice: 0.9495,Test IoU: 0.8647, Test Dice: 0.9102, Train Acc: 0.9979, Test Acc: 0.9960\n",
      "Epoch [112/200], Avg Loss: 0.11149, Avg IoU: 0.9233, Avg Dice: 0.9500,Test IoU: 0.8665, Test Dice: 0.9115, Train Acc: 0.9979, Test Acc: 0.9961\n",
      "Epoch [113/200], Avg Loss: 0.11150, Avg IoU: 0.9251, Avg Dice: 0.9511,Test IoU: 0.8671, Test Dice: 0.9118, Train Acc: 0.9980, Test Acc: 0.9961\n",
      "Epoch [114/200], Avg Loss: 0.11150, Avg IoU: 0.9247, Avg Dice: 0.9508,Test IoU: 0.8670, Test Dice: 0.9116, Train Acc: 0.9980, Test Acc: 0.9961\n",
      "Epoch [115/200], Avg Loss: 0.11150, Avg IoU: 0.9255, Avg Dice: 0.9513,Test IoU: 0.8669, Test Dice: 0.9117, Train Acc: 0.9980, Test Acc: 0.9961\n",
      "Epoch [116/200], Avg Loss: 0.11150, Avg IoU: 0.9250, Avg Dice: 0.9510,Test IoU: 0.8659, Test Dice: 0.9109, Train Acc: 0.9980, Test Acc: 0.9960\n",
      "Epoch [117/200], Avg Loss: 0.11149, Avg IoU: 0.9249, Avg Dice: 0.9510,Test IoU: 0.8677, Test Dice: 0.9121, Train Acc: 0.9980, Test Acc: 0.9961\n",
      "Epoch [118/200], Avg Loss: 0.11150, Avg IoU: 0.9255, Avg Dice: 0.9513,Test IoU: 0.8703, Test Dice: 0.9137, Train Acc: 0.9980, Test Acc: 0.9963\n",
      "Epoch [119/200], Avg Loss: 0.11149, Avg IoU: 0.9255, Avg Dice: 0.9513,Test IoU: 0.8668, Test Dice: 0.9116, Train Acc: 0.9980, Test Acc: 0.9961\n",
      "Epoch [120/200], Avg Loss: 0.11149, Avg IoU: 0.9263, Avg Dice: 0.9518,Test IoU: 0.8711, Test Dice: 0.9142, Train Acc: 0.9980, Test Acc: 0.9963\n",
      "Epoch [121/200], Avg Loss: 0.11150, Avg IoU: 0.9261, Avg Dice: 0.9517,Test IoU: 0.8622, Test Dice: 0.9088, Train Acc: 0.9980, Test Acc: 0.9958\n",
      "Epoch [122/200], Avg Loss: 0.11149, Avg IoU: 0.9263, Avg Dice: 0.9518,Test IoU: 0.8672, Test Dice: 0.9118, Train Acc: 0.9980, Test Acc: 0.9961\n",
      "Epoch [123/200], Avg Loss: 0.11149, Avg IoU: 0.9273, Avg Dice: 0.9524,Test IoU: 0.8723, Test Dice: 0.9151, Train Acc: 0.9981, Test Acc: 0.9963\n",
      "Epoch [124/200], Avg Loss: 0.11149, Avg IoU: 0.9279, Avg Dice: 0.9527,Test IoU: 0.8679, Test Dice: 0.9125, Train Acc: 0.9981, Test Acc: 0.9961\n",
      "Epoch [125/200], Avg Loss: 0.11150, Avg IoU: 0.9276, Avg Dice: 0.9526,Test IoU: 0.8661, Test Dice: 0.9111, Train Acc: 0.9981, Test Acc: 0.9960\n",
      "Epoch [126/200], Avg Loss: 0.11149, Avg IoU: 0.9275, Avg Dice: 0.9524,Test IoU: 0.8668, Test Dice: 0.9116, Train Acc: 0.9981, Test Acc: 0.9961\n",
      "Epoch [127/200], Avg Loss: 0.11149, Avg IoU: 0.9288, Avg Dice: 0.9532,Test IoU: 0.8691, Test Dice: 0.9131, Train Acc: 0.9981, Test Acc: 0.9962\n",
      "Epoch [128/200], Avg Loss: 0.11149, Avg IoU: 0.9286, Avg Dice: 0.9531,Test IoU: 0.8665, Test Dice: 0.9117, Train Acc: 0.9981, Test Acc: 0.9960\n",
      "Epoch [129/200], Avg Loss: 0.11149, Avg IoU: 0.9282, Avg Dice: 0.9528,Test IoU: 0.8677, Test Dice: 0.9124, Train Acc: 0.9981, Test Acc: 0.9961\n",
      "Epoch [130/200], Avg Loss: 0.11150, Avg IoU: 0.9277, Avg Dice: 0.9525,Test IoU: 0.8671, Test Dice: 0.9119, Train Acc: 0.9981, Test Acc: 0.9961\n",
      "Epoch [131/200], Avg Loss: 0.11149, Avg IoU: 0.9282, Avg Dice: 0.9529,Test IoU: 0.8661, Test Dice: 0.9113, Train Acc: 0.9981, Test Acc: 0.9960\n",
      "Epoch [132/200], Avg Loss: 0.11150, Avg IoU: 0.9286, Avg Dice: 0.9531,Test IoU: 0.8686, Test Dice: 0.9128, Train Acc: 0.9981, Test Acc: 0.9962\n",
      "Epoch [133/200], Avg Loss: 0.11149, Avg IoU: 0.9298, Avg Dice: 0.9537,Test IoU: 0.8685, Test Dice: 0.9128, Train Acc: 0.9982, Test Acc: 0.9961\n",
      "Epoch [134/200], Avg Loss: 0.11149, Avg IoU: 0.9301, Avg Dice: 0.9539,Test IoU: 0.8664, Test Dice: 0.9115, Train Acc: 0.9982, Test Acc: 0.9961\n",
      "Epoch [135/200], Avg Loss: 0.11149, Avg IoU: 0.9292, Avg Dice: 0.9534,Test IoU: 0.8656, Test Dice: 0.9113, Train Acc: 0.9982, Test Acc: 0.9960\n",
      "Epoch [136/200], Avg Loss: 0.11150, Avg IoU: 0.9301, Avg Dice: 0.9540,Test IoU: 0.8678, Test Dice: 0.9121, Train Acc: 0.9982, Test Acc: 0.9962\n",
      "Epoch [137/200], Avg Loss: 0.11149, Avg IoU: 0.9304, Avg Dice: 0.9541,Test IoU: 0.8679, Test Dice: 0.9124, Train Acc: 0.9982, Test Acc: 0.9961\n",
      "Epoch [138/200], Avg Loss: 0.11149, Avg IoU: 0.9305, Avg Dice: 0.9541,Test IoU: 0.8667, Test Dice: 0.9116, Train Acc: 0.9982, Test Acc: 0.9961\n",
      "Epoch [139/200], Avg Loss: 0.11150, Avg IoU: 0.9311, Avg Dice: 0.9545,Test IoU: 0.8674, Test Dice: 0.9122, Train Acc: 0.9982, Test Acc: 0.9961\n",
      "Epoch [140/200], Avg Loss: 0.11149, Avg IoU: 0.9312, Avg Dice: 0.9546,Test IoU: 0.8690, Test Dice: 0.9131, Train Acc: 0.9982, Test Acc: 0.9962\n",
      "Epoch [141/200], Avg Loss: 0.11150, Avg IoU: 0.9308, Avg Dice: 0.9544,Test IoU: 0.8709, Test Dice: 0.9142, Train Acc: 0.9982, Test Acc: 0.9963\n",
      "Epoch [142/200], Avg Loss: 0.11149, Avg IoU: 0.9298, Avg Dice: 0.9536,Test IoU: 0.8667, Test Dice: 0.9115, Train Acc: 0.9982, Test Acc: 0.9960\n",
      "Epoch [143/200], Avg Loss: 0.11149, Avg IoU: 0.9302, Avg Dice: 0.9539,Test IoU: 0.8692, Test Dice: 0.9132, Train Acc: 0.9982, Test Acc: 0.9962\n",
      "Epoch [144/200], Avg Loss: 0.11149, Avg IoU: 0.9313, Avg Dice: 0.9546,Test IoU: 0.8670, Test Dice: 0.9115, Train Acc: 0.9982, Test Acc: 0.9961\n",
      "Epoch [145/200], Avg Loss: 0.11149, Avg IoU: 0.9321, Avg Dice: 0.9550,Test IoU: 0.8694, Test Dice: 0.9133, Train Acc: 0.9983, Test Acc: 0.9962\n",
      "Epoch [146/200], Avg Loss: 0.11149, Avg IoU: 0.9333, Avg Dice: 0.9556,Test IoU: 0.8692, Test Dice: 0.9131, Train Acc: 0.9983, Test Acc: 0.9962\n",
      "Epoch [147/200], Avg Loss: 0.11150, Avg IoU: 0.9328, Avg Dice: 0.9554,Test IoU: 0.8706, Test Dice: 0.9139, Train Acc: 0.9983, Test Acc: 0.9963\n",
      "Epoch [148/200], Avg Loss: 0.11149, Avg IoU: 0.9329, Avg Dice: 0.9554,Test IoU: 0.8702, Test Dice: 0.9138, Train Acc: 0.9983, Test Acc: 0.9962\n",
      "Epoch [149/200], Avg Loss: 0.11149, Avg IoU: 0.9323, Avg Dice: 0.9551,Test IoU: 0.8673, Test Dice: 0.9120, Train Acc: 0.9983, Test Acc: 0.9961\n",
      "Epoch [150/200], Avg Loss: 0.11149, Avg IoU: 0.9323, Avg Dice: 0.9552,Test IoU: 0.8684, Test Dice: 0.9126, Train Acc: 0.9983, Test Acc: 0.9962\n",
      "Epoch [151/200], Avg Loss: 0.11149, Avg IoU: 0.9325, Avg Dice: 0.9553,Test IoU: 0.8666, Test Dice: 0.9116, Train Acc: 0.9983, Test Acc: 0.9960\n",
      "Epoch [152/200], Avg Loss: 0.11149, Avg IoU: 0.9323, Avg Dice: 0.9551,Test IoU: 0.8669, Test Dice: 0.9113, Train Acc: 0.9983, Test Acc: 0.9961\n",
      "Epoch [153/200], Avg Loss: 0.11150, Avg IoU: 0.9328, Avg Dice: 0.9554,Test IoU: 0.8672, Test Dice: 0.9119, Train Acc: 0.9983, Test Acc: 0.9961\n",
      "Epoch [154/200], Avg Loss: 0.11149, Avg IoU: 0.9336, Avg Dice: 0.9559,Test IoU: 0.8679, Test Dice: 0.9125, Train Acc: 0.9983, Test Acc: 0.9961\n",
      "Epoch [155/200], Avg Loss: 0.11149, Avg IoU: 0.9337, Avg Dice: 0.9559,Test IoU: 0.8693, Test Dice: 0.9133, Train Acc: 0.9983, Test Acc: 0.9962\n",
      "Epoch [156/200], Avg Loss: 0.11150, Avg IoU: 0.9341, Avg Dice: 0.9561,Test IoU: 0.8689, Test Dice: 0.9129, Train Acc: 0.9983, Test Acc: 0.9961\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 88\u001b[0m\n\u001b[0;32m     85\u001b[0m     confidence \u001b[39m=\u001b[39m \u001b[39m0.9\u001b[39m\n\u001b[0;32m     87\u001b[0m \u001b[39mfor\u001b[39;00m images, labels \u001b[39min\u001b[39;00m dataloader:\n\u001b[1;32m---> 88\u001b[0m     images \u001b[39m=\u001b[39m images\u001b[39m.\u001b[39;49mto(device)\n\u001b[0;32m     89\u001b[0m     labels \u001b[39m=\u001b[39m labels\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     91\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# UNet++ Train and Test Set\n",
    "# -----------------------------\n",
    "\n",
    "# empty the cache for model and training process\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# set the hyper parameters and the paths 设置超参数和路径\n",
    "data_path = \"./dataset/Spineweb_dataset15/train/\"\n",
    "test_path = \"./dataset/Spineweb_dataset15/test/\"\n",
    "\n",
    "#hyper parameters set\n",
    "batch_size = 8\n",
    "num_epochs = 200\n",
    "learning_rate = 1e-04\n",
    "confidence = 0.7\n",
    "poster_threshold = 200\n",
    "in_channels = 1  # according to demand to adjust the number of channels 根据实际情况修改通道数\n",
    "out_channels = 1  # according to demand to adjust the number of channels 根据实际情况修改通道数\n",
    "\n",
    "# 创建数据集和数据加载器\n",
    "transform = transforms.Compose([\n",
    "    # transforms.ToPILImage(),  # 转换为 PIL 图像对象\n",
    "    transforms.Resize((256, 256)),  # 调整大小为 128x128\n",
    "    transforms.ToTensor()  # 转换为张量\n",
    "])\n",
    "\n",
    "dataset = SpineWeb15(data_path=data_path, transform1=transform, transform2=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "testset = SpineWeb15(data_path=test_path, transform1=transform, transform2=transform)\n",
    "test_loader = DataLoader(testset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# 创建模型和优化器\n",
    "model = smp.UnetPlusPlus(encoder_name='resnet34', encoder_depth=5, encoder_weights=\"imagenet\", decoder_use_batchnorm=True, decoder_channels=(256, 128, 64, 32, 16), decoder_attention_type=None, in_channels=1, classes=1, activation=None, aux_params=None)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "# criterion = nn.BCEWithLogitsLoss()  # 二分类任务可以使用BCEWithLogitsLoss\n",
    "# criterion = DiceLoss(mode=\"binary\")   #DiceLoss\n",
    "# criterion = FocalLoss(mode=\"binary\")\n",
    "criterion = smp.losses.TverskyLoss(mode=\"binary\")\n",
    "# criterion = smp.losses.LovaszLoss(mode=\"binary\")\n",
    "\n",
    "# 设置设备\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# check the parameters of the model could be trained 检查模型的参数是否设置为可训练\n",
    "# for name, param in model.named_parameters():\n",
    "#     print(f\"Parameter: {name}, Requires Grad: {param.requires_grad}\")\n",
    "\n",
    "best_loss_train = 100.0\n",
    "best_IoU_train = 0.0\n",
    "best_Dice_train = 0.0\n",
    "\n",
    "best_IoU_test = 0.0\n",
    "best_Dice_test = 0.0\n",
    "\n",
    "best_acc_train = 0.0\n",
    "best_acc_test = 0.0\n",
    "\n",
    "loss_train_list = []\n",
    "IoU_train_list = []\n",
    "Dice_train_list = []\n",
    "IoU_test_list = []\n",
    "Dice_test_list = []\n",
    "acc_train_list = []\n",
    "acc_test_list = []\n",
    "\n",
    "# 训练模型\n",
    "for epoch in range(num_epochs):\n",
    "    # torch.cuda.empty_cache()\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    total_iou = 0.0\n",
    "    total_dice = 0.0\n",
    "    total_iou_test = 0.0\n",
    "    total_dice_test = 0.0\n",
    "    total_acc_train = 0.0\n",
    "    total_acc_test = 0.0\n",
    "    total_correct_pixels = 0\n",
    "    total_pixels = 0\n",
    "    total_correct_pixels_test = 0\n",
    "    total_pixels_test = 0\n",
    "\n",
    "    if epoch > 100:\n",
    "        confidence = 0.9\n",
    "\n",
    "    for images, labels in dataloader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(images)\n",
    "        # squeeze the dimension that pytorch add for channels\n",
    "        outputs = outputs.squeeze(1)     # tensor size ([16,128,128])\n",
    "        labels = labels.squeeze(1)\n",
    "        labels = labels * 255\n",
    "        labels[labels <= poster_threshold] = 0\n",
    "        labels[labels > poster_threshold] = 1\n",
    "        # apply sigmoid on the outputs\n",
    "        outputs = torch.sigmoid(outputs)\n",
    "        # process the result, bigger than confidence is reliable\n",
    "        predicted = (outputs > confidence).float()     # tensor size ([16,128,128]), True->1.0 and False->0.0\n",
    "        intersection = torch.logical_and(predicted, labels).sum((1, 2))\n",
    "        union = torch.logical_or(predicted, labels).sum((1, 2))\n",
    "        iou = (intersection / (union + 1e-7))  # 每个样本的IoU\n",
    "        dice = (2 * intersection / (predicted.sum((1, 2)) + labels.sum((1, 2))+1e-7))  # 每个样本的Dice Coefficient\n",
    "        # 计算训练集的像素精度\n",
    "        batch_correct_pixels,bacth_total_pixels = calculate_pixel_accuracy(predicted, labels)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        total_iou += torch.sum(iou).item()\n",
    "        total_dice += torch.sum(dice).item()\n",
    "        total_correct_pixels += batch_correct_pixels\n",
    "        total_pixels += bacth_total_pixels\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # train set results\n",
    "    avg_loss = train_loss / len(dataset)\n",
    "    avg_iou = total_iou / len(dataset)\n",
    "    avg_dice = total_dice / len(dataset)\n",
    "    avg_acc_train = total_correct_pixels / total_pixels\n",
    "\n",
    "    # test set results\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_loader:     \n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            targets = targets * 255\n",
    "            targets[targets <= poster_threshold] = 0\n",
    "            targets[targets > poster_threshold] = 1\n",
    "            outputs = model(inputs)\n",
    "            # squeeze the dimension that pytorch add for channels\n",
    "            outputs = outputs.squeeze(1)     # tensor size ([16,128,128])\n",
    "            targets = targets.squeeze(1)\n",
    "            outputs = torch.sigmoid(outputs)\n",
    "            # process the result, bigger than 0.5 is reliable\n",
    "            predicted = (outputs > confidence).float()     # tensor size ([16,128,128])\n",
    "            intersection = torch.logical_and(predicted, targets).sum((1, 2))\n",
    "            union = torch.logical_or(predicted, targets).sum((1, 2))\n",
    "            iou = (intersection / (union + 1e-7))  # 每个样本的IoU\n",
    "            dice = (2 * intersection / (predicted.sum((1, 2)) + targets.sum((1, 2))+1e-7))  # 每个样本的Dice Coefficient\n",
    "\n",
    "\n",
    "            batch_correct_pixels,batch_total_pixels = calculate_pixel_accuracy(predicted, targets)\n",
    "            total_iou_test += torch.sum(iou).item()\n",
    "            total_dice_test += torch.sum(dice).item()\n",
    "            total_correct_pixels_test += batch_correct_pixels\n",
    "            total_pixels_test += batch_total_pixels\n",
    "\n",
    "    test_iou = total_iou_test / len(testset)\n",
    "    test_dice = total_dice_test / len(testset)\n",
    "    test_acc = total_correct_pixels_test / total_pixels_test\n",
    "\n",
    "    # get the best IoU and Dice\n",
    "    best_loss_train = best_loss_train if best_loss_train < avg_loss else avg_loss\n",
    "    best_IoU_train = best_IoU_train if best_IoU_train > avg_iou else avg_iou\n",
    "    best_Dice_train = best_Dice_train if best_Dice_train > avg_dice else avg_dice\n",
    "    best_IoU_test = best_IoU_test if best_IoU_test > test_iou else test_iou\n",
    "    # best_Dice_test = best_Dice_test if best_Dice_test > test_dice else test_dice\n",
    "\n",
    "    if(best_Dice_test <= test_dice):\n",
    "        best_Dice_test = test_dice\n",
    "        torch.save(model.state_dict(), f\"./model/UNet++256_checkpoint.pth\")\n",
    "\n",
    "    # get the best accuracy of the trainloader and testloader\n",
    "    best_acc_train = best_acc_train if best_acc_train > avg_acc_train else avg_acc_train\n",
    "    best_acc_test = best_acc_test if best_acc_test > test_acc else test_acc\n",
    "\n",
    "    # store the data in each epoch\n",
    "    loss_train_list.append(avg_loss)\n",
    "    IoU_train_list.append(avg_iou)\n",
    "    Dice_train_list.append(avg_dice)\n",
    "    IoU_test_list.append(test_iou)\n",
    "    Dice_test_list.append(test_dice)\n",
    "    acc_train_list.append(avg_acc_train)\n",
    "    acc_test_list.append(test_acc)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Avg Loss: {avg_loss:.5f}, Avg IoU: {avg_iou:.4f}, Avg Dice: {avg_dice:.4f},Test IoU: {test_iou:.4f}, Test Dice: {test_dice:.4f}, Train Acc: {avg_acc_train:.4f}, Test Acc: {test_acc:.4f}\")\n",
    "    \n",
    "print(\"-----------------------------------------\")\n",
    "print(f\"Best Loss: {best_loss_train:.4f}, Best Train IoU: {best_IoU_train:.4f}, Best Train Dice: {best_Dice_train:.4f}, Best Test IoU: {best_IoU_test:.4f}, Best Test Dice: {best_Dice_test:.4f}, Best Train Acc: {best_acc_train:.4f}, Best Test Acc: {best_acc_test:.4f}\")\n",
    "# draw the plot for the loss and dice\n",
    "# 定义epochs的数量，用于x轴坐标\n",
    "epochs = len(loss_train_list)\n",
    "fit,(ax1,ax2) = plt.subplots(2,1,figsize=(8,8))\n",
    "# 绘制训练损失曲线\n",
    "ax1.plot(range(1, epochs + 1), loss_train_list, label='Train Loss')\n",
    "# 设置图例1\n",
    "ax1.legend()\n",
    "ax1.set_xlabel('Epochs')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('Training Loss')\n",
    "ax1.grid(True)\n",
    "# 绘制IoU和Dice\n",
    "ax2.plot(range(1,epochs +1),IoU_train_list,label='Train IoU')\n",
    "ax2.plot(range(1,epochs +1),Dice_train_list,label='Train Dice')\n",
    "# 设置图例2\n",
    "ax2.legend()\n",
    "ax2.set_xlabel('Epochs')\n",
    "ax2.set_ylabel('IoU and Dice')\n",
    "ax2.set_title('Training IoU and Dice')\n",
    "ax2.grid(True)# show the plots\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# empty the cache for model and training process\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 768.00 MiB (GPU 0; 4.00 GiB total capacity; 2.20 GiB already allocated; 0 bytes free; 2.93 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 50\u001b[0m\n\u001b[0;32m     48\u001b[0m targets[targets \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m poster_threshold] \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m     49\u001b[0m targets[targets \u001b[39m>\u001b[39m poster_threshold] \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m---> 50\u001b[0m outputs \u001b[39m=\u001b[39m model(inputs)\n\u001b[0;32m     51\u001b[0m \u001b[39m# squeeze the dimension that pytorch add for channels\u001b[39;00m\n\u001b[0;32m     52\u001b[0m outputs \u001b[39m=\u001b[39m outputs\u001b[39m.\u001b[39msqueeze(\u001b[39m1\u001b[39m)     \u001b[39m# tensor size ([16,128,128])\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\manjw\\.conda\\envs\\dataEngineering\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\manjw\\.conda\\envs\\dataEngineering\\Lib\\site-packages\\segmentation_models_pytorch\\base\\model.py:30\u001b[0m, in \u001b[0;36mSegmentationModel.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_input_shape(x)\n\u001b[0;32m     29\u001b[0m features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder(x)\n\u001b[1;32m---> 30\u001b[0m decoder_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecoder(\u001b[39m*\u001b[39;49mfeatures)\n\u001b[0;32m     32\u001b[0m masks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msegmentation_head(decoder_output)\n\u001b[0;32m     34\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclassification_head \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\manjw\\.conda\\envs\\dataEngineering\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\manjw\\.conda\\envs\\dataEngineering\\Lib\\site-packages\\segmentation_models_pytorch\\decoders\\unetplusplus\\decoder.py:135\u001b[0m, in \u001b[0;36mUnetPlusPlusDecoder.forward\u001b[1;34m(self, *features)\u001b[0m\n\u001b[0;32m    133\u001b[0m             cat_features \u001b[39m=\u001b[39m [dense_x[\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mx_\u001b[39m\u001b[39m{\u001b[39;00midx\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00mdense_l_i\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(depth_idx \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, dense_l_i \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m)]\n\u001b[0;32m    134\u001b[0m             cat_features \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat(cat_features \u001b[39m+\u001b[39m [features[dense_l_i \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m]], dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m--> 135\u001b[0m             dense_x[\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mx_\u001b[39m\u001b[39m{\u001b[39;00mdepth_idx\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00mdense_l_i\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mblocks[\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mx_\u001b[39;49m\u001b[39m{\u001b[39;49;00mdepth_idx\u001b[39m}\u001b[39;49;00m\u001b[39m_\u001b[39;49m\u001b[39m{\u001b[39;49;00mdense_l_i\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m](\n\u001b[0;32m    136\u001b[0m                 dense_x[\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mx_\u001b[39;49m\u001b[39m{\u001b[39;49;00mdepth_idx\u001b[39m}\u001b[39;49;00m\u001b[39m_\u001b[39;49m\u001b[39m{\u001b[39;49;00mdense_l_i\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m], cat_features\n\u001b[0;32m    137\u001b[0m             )\n\u001b[0;32m    138\u001b[0m dense_x[\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mx_\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m0\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdepth\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblocks[\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mx_\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m0\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdepth\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m](dense_x[\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mx_\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m0\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdepth\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m])\n\u001b[0;32m    139\u001b[0m \u001b[39mreturn\u001b[39;00m dense_x[\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mx_\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m0\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdepth\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\manjw\\.conda\\envs\\dataEngineering\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\manjw\\.conda\\envs\\dataEngineering\\Lib\\site-packages\\segmentation_models_pytorch\\decoders\\unetplusplus\\decoder.py:38\u001b[0m, in \u001b[0;36mDecoderBlock.forward\u001b[1;34m(self, x, skip)\u001b[0m\n\u001b[0;32m     36\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39minterpolate(x, scale_factor\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, mode\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mnearest\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     37\u001b[0m \u001b[39mif\u001b[39;00m skip \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m---> 38\u001b[0m     x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mcat([x, skip], dim\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m     39\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mattention1(x)\n\u001b[0;32m     40\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv1(x)\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 768.00 MiB (GPU 0; 4.00 GiB total capacity; 2.20 GiB already allocated; 0 bytes free; 2.93 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "# Using the best model to evaluate on the test set\n",
    "\n",
    "model = smp.UnetPlusPlus(encoder_name='resnet34', encoder_depth=5, encoder_weights=\"imagenet\", decoder_use_batchnorm=True, decoder_channels=(256, 128, 64, 32, 16), decoder_attention_type=None, in_channels=1, classes=1, activation=None, aux_params=None)\n",
    "\n",
    "# 设置设备\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "test_path = \"./dataset/Spineweb_dataset15/test/\"\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    # transforms.ToPILImage(),  # 转换为 PIL 图像对象\n",
    "    transforms.Resize((256, 256)),  # 调整大小为 128x128\n",
    "    transforms.ToTensor()  # 转换为张量\n",
    "])\n",
    "\n",
    "# 加载已保存的模型参数\n",
    "checkpoint_path = \"./model/UNet++256_checkpoint.pth\"  # 模型文件路径\n",
    "checkpoint = torch.load(checkpoint_path)\n",
    "model.load_state_dict(checkpoint)\n",
    "\n",
    "# 设置模型为推理模式\n",
    "model.eval()\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "confidence = 0.9\n",
    "\n",
    "testset = SpineWeb15(data_path=test_path, transform1=transform,transform2=transform)\n",
    "test_loader = DataLoader(testset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# data_iter = iter(test_loader)\n",
    "# images, labels = next(data_iter)\n",
    "# print(\"加载的样本数量:\", images.shape[0])\n",
    "\n",
    "total_iou_test = 0.0\n",
    "total_dice_test = 0.0\n",
    "total_acc_test = 0.0\n",
    "total_correct_pixels_test = 0\n",
    "total_pixels_test = 0\n",
    "\n",
    "# test set results\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        targets = targets * 255\n",
    "        targets[targets <= poster_threshold] = 0\n",
    "        targets[targets > poster_threshold] = 1\n",
    "        outputs = model(inputs)\n",
    "        # squeeze the dimension that pytorch add for channels\n",
    "        outputs = outputs.squeeze(1)     # tensor size ([16,128,128])\n",
    "        targets = targets.squeeze(1)\n",
    "        outputs = torch.sigmoid(outputs)\n",
    "        # process the result, bigger than 0.5 is reliable\n",
    "        predicted = (outputs > confidence).float()     # tensor size ([16,128,128])\n",
    "        intersection = torch.logical_and(predicted, targets).sum((1, 2))\n",
    "        union = torch.logical_or(predicted, targets).sum((1, 2))\n",
    "        iou = (intersection / (union + 1e-7))  # 平均每个样本的IoU\n",
    "        dice = (2 * intersection / (predicted.sum((1, 2)) + targets.sum((1, 2))+1e-7))  # 平均每个样本的Dice Coefficient\n",
    "\n",
    "\n",
    "        batch_correct_pixels,batch_total_pixels = calculate_pixel_accuracy(predicted, targets)\n",
    "        total_iou_test += torch.sum(iou).item()\n",
    "        total_dice_test += torch.sum(dice).item()\n",
    "        total_correct_pixels_test += batch_correct_pixels\n",
    "        total_pixels_test += batch_total_pixels\n",
    "        \n",
    "inputs_npimage = inputs.squeeze(1)[0].detach().cpu().numpy()\n",
    "predicted_npimage = predicted[0].detach().cpu().numpy()\n",
    "targets_npimage = targets[0].detach().cpu().numpy()\n",
    "fig, axes = plt.subplots(3, 1)\n",
    "axes[0].imshow(inputs_npimage, cmap='gray')\n",
    "axes[0].set_title('Original')\n",
    "axes[1].imshow(predicted_npimage, cmap='gray')\n",
    "axes[1].set_title('Predicted')\n",
    "axes[2].imshow(targets_npimage, cmap='gray')\n",
    "axes[2].set_title('Target')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "test_iou = total_iou_test / len(testset)\n",
    "test_dice = total_dice_test / len(testset)\n",
    "test_acc = total_correct_pixels_test / total_pixels_test\n",
    "\n",
    "# output the result, the result may vary a little due to the resize function in transform\n",
    "print(f\"Best Test IoU: {test_iou:.4f}, Best Test Dice: {test_dice:.4f} Best Test Acc: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Train IoU: 0.9526, Best Train Dice: 0.9663 Best Train Acc: 0.9990\n"
     ]
    }
   ],
   "source": [
    "# Using the best model to evaluate on the train set\n",
    "\n",
    "model = smp.UnetPlusPlus(encoder_name='resnet34', encoder_depth=5, encoder_weights=\"imagenet\", decoder_use_batchnorm=True, decoder_channels=(256, 128, 64, 32, 16), decoder_attention_type=None, in_channels=1, classes=1, activation=None, aux_params=None)\n",
    "\n",
    "# 设置设备\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "test_path = \"./dataset/Spineweb_dataset15/train/\"\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    # transforms.ToPILImage(),  # 转换为 PIL 图像对象\n",
    "    transforms.Resize((256, 256)),  # 调整大小为 128x128\n",
    "    transforms.ToTensor()  # 转换为张量\n",
    "])\n",
    "\n",
    "# 加载已保存的模型参数\n",
    "checkpoint_path = \"./model/UNet++256_checkpoint.pth\"  # 模型文件路径\n",
    "checkpoint = torch.load(checkpoint_path)\n",
    "model.load_state_dict(checkpoint)\n",
    "\n",
    "# 设置模型为推理模式\n",
    "model.eval()\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "confidence = 0.9\n",
    "\n",
    "testset = SpineWeb15(data_path=test_path, transform1=transform, transform2=transform)\n",
    "test_loader = DataLoader(testset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# data_iter = iter(test_loader)\n",
    "# images, labels = next(data_iter)\n",
    "# print(\"加载的样本数量:\", images.shape[0])\n",
    "\n",
    "total_iou_test = 0.0\n",
    "total_dice_test = 0.0\n",
    "total_acc_test = 0.0\n",
    "total_correct_pixels_test = 0\n",
    "total_pixels_test = 0\n",
    "\n",
    "# test set results\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        targets = targets * 255\n",
    "        targets[targets <= poster_threshold] = 0\n",
    "        targets[targets > poster_threshold] = 1\n",
    "        outputs = model(inputs)\n",
    "        # squeeze the dimension that pytorch add for channels\n",
    "        outputs = outputs.squeeze(1)     # tensor size ([16,128,128])\n",
    "        targets = targets.squeeze(1)\n",
    "        outputs = torch.sigmoid(outputs)\n",
    "        # process the result, bigger than 0.5 is reliable\n",
    "        predicted = (outputs > confidence).float()     # tensor size ([16,128,128])\n",
    "        intersection = torch.logical_and(predicted, targets).sum((1, 2))\n",
    "        union = torch.logical_or(predicted, targets).sum((1, 2))\n",
    "        iou = (intersection / (union + 1e-7))  # 平均每个样本的IoU\n",
    "        dice = (2 * intersection / (predicted.sum((1, 2)) + targets.sum((1, 2))+1e-7))  # 平均每个样本的Dice Coefficient\n",
    "\n",
    "\n",
    "        batch_correct_pixels,batch_total_pixels = calculate_pixel_accuracy(predicted, targets)\n",
    "        total_iou_test += torch.sum(iou).item()\n",
    "        total_dice_test += torch.sum(dice).item()\n",
    "        total_correct_pixels_test += batch_correct_pixels\n",
    "        total_pixels_test += batch_total_pixels\n",
    "        \n",
    "\n",
    "inputs_npimage = inputs.squeeze(1)[0].detach().cpu().numpy()\n",
    "predicted_npimage = predicted[0].detach().cpu().numpy()\n",
    "targets_npimage = targets[0].detach().cpu().numpy()\n",
    "fig, axes = plt.subplots(3, 1)\n",
    "axes[0].imshow(inputs_npimage, cmap='gray')\n",
    "axes[0].set_title('Original')\n",
    "axes[1].imshow(predicted_npimage, cmap='gray')\n",
    "axes[1].set_title('Predicted')\n",
    "axes[2].imshow(targets_npimage, cmap='gray')\n",
    "axes[2].set_title('Target')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "test_iou = total_iou_test / len(testset)\n",
    "test_dice = total_dice_test / len(testset)\n",
    "test_acc = total_correct_pixels_test / total_pixels_test\n",
    "\n",
    "# output the result, the result may vary a little due to the resize function in transform\n",
    "print(f\"Best Train IoU: {test_iou:.4f}, Best Train Dice: {test_dice:.4f} Best Train Acc: {test_acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataEngineering",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
